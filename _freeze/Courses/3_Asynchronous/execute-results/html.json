{
  "hash": "ce5e97914718655422eae041319b6a74",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Asynchronous Programming with Python\nsubtitle: One programming model to rule them all\nnocite: |\n    @fowler2022python\n---\n\n\n# Asynchronous, Basics\n\n## What is Asynchronous Programming?\n\n- Asynchronous programming is a programming paradigm that allows the program to continue executing other tasks before the current task is finished.\n- It is a way to achieve concurrency in a program.\n\n$\\Rightarrow$  it is an **abstraction over concurrency**, it does not necessarily mean that the program is executed in parallel.\n\n## I/O Bound vs. CPU Bound\n\n```python\nimport requests\n \nresponse = requests.get('https://www.example.com')      #<1>\n \nitems = response.headers.items()\n \nheaders = [f'{key}: {header}' for key, header in items] #<2>\n \nformatted_headers = '\\n'.join(headers)                  #<3>\n \nwith open('headers.txt', 'w') as file:\n    file.write(formatted_headers)                       #<4>\n```\n1. I/O-bound web request\n2. CPU-bound response processing\n3. CPU-bound string concatenation\n4. I/O-bound write to disk\n\n# Concurrency, parallelism and multitasking\n\nWe will use extensively the bakery metaphor.\n\n\n## Concurrency vs. Parallelism\n\n::: {.columns}\n:::: {.column width=50%}\nOne baker and two cakes to prepare.\n\n- Can preheat the oven while preparing the first cake.\n- Can start the second cake while the first one is in the oven.\n\n$\\Rightarrow$ **Switching between tasks** is **concurrency** (or concurrent behavior).\n::::\n\n:::: {.column width=50%}\nTwo bakers and two cakes to prepare.\n\n- Can prepare both cakes at the same time.\n\n$\\Rightarrow$ **Doing multiple tasks in parallel** is **parallelism** (or parallel behavior).\n::::\n:::\n\n## Concurrency vs. Parallelism (2)\n\n![With concurrency, we have multiple tasks happening at the same time, but only one weâ€™re actively doing at a given point in time. With parallelism, we have multiple tasks happening and are actively doing more than one simultaneously.](d2-figures/bakers.svg)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Concurrency vs. Parallelism (3)\n\n![With concurrency, we switch between running two applications. With parallelism, we actively run two applications simultaneously.](d2-figures/concurrency.svg)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Concurrency vs. Parallelism (4)\n\n- Concurrency is about multiple **independent** tasks that can happen.\n- Parallelism is concurrency AND **simultaneous** execution.\n\nWhile parallelism implies concurrency, concurrency does not always imply parallelism.\n\n$\\Rightarrow$ Concurrency is a **broader** concept than parallelism.\n\n## Multitasking\n\n::: {.columns}\n:::: {.column width=50%}\n### Preemptive multitasking\n\n- The operating system decides when to switch between tasks.\n- The tasks are not aware of each other.\n\n::::\n\n:::: {.column width=50%}\n### Cooperative multitasking\n\n- In this model we have to explicitly to decide when to switch between tasks.\n- The tasks are aware of each other.\n\n::::\n:::\n\n## Benefits of cooperative multitasking\n\n- Less overhead than preemptive multitasking.\n- Granular/optimal control over when to switch between tasks.\n\n# Processes, threads, multithreading, and multiprocessing\n\n## Multi-processing vs Multi-threading \n\n:::{layout-ncol=\"2\"}\n\n![Multi-Processing](tikz-figures/multiprocessing_model.svg)\n\n![Multi-Threading](tikz-figures/multithreading_model.svg)\n\n:::\n\n## Processes and threads\n\n::: {#c5a1a7ea .cell output-location='fragment' execution_count=2}\n``` {.python .cell-code lst-cap=\"Processes and threads in a simple Python application\"}\nimport os\nimport threading\n \nprint(f'Python process running with process id: {os.getpid()}')\ntotal_threads = threading.active_count()\nthread_name = threading.current_thread().name\n \nprint(f'Python is currently running {total_threads} thread(s)')\nprint(f'The current thread is {thread_name}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPython process running with process id: 119943\nPython is currently running 8 thread(s)\nThe current thread is MainThread\n```\n:::\n:::\n\n\n## Creating processes\n\n::: {#245a2049 .cell output-location='fragment' execution_count=3}\n``` {.python .cell-code lst-cap=\"Creating processes in Python\"}\nimport multiprocessing\nimport os\n \n \ndef hello_from_process():\n    print(f'Hello from child process {os.getpid()}!')\nif __name__ == '__main__':\n    hello_process = multiprocessing.Process(target=hello_from_process)\n    hello_process.start()\n \n    print(f'Hello from parent process {os.getpid()}')\n \n    hello_process.join()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello from child process 119972!\nHello from parent process 119943\n```\n:::\n:::\n\n\n## Creating threads\n\n::: {#6ba8679a .cell output-location='fragment' execution_count=4}\n``` {.python .cell-code lst-cap=\"Creating threads in Python\"}\nimport threading\n \n \ndef hello_from_thread():\n    print(f'Hello from thread {threading.current_thread()}!')\n \n \nhello_thread = threading.Thread(target=hello_from_thread)\nhello_thread.start()\n \ntotal_threads = threading.active_count()\nthread_name = threading.current_thread().name\n \nprint(f'Python is currently running {total_threads} thread(s)')\nprint(f'The current thread is {thread_name}')\n \nhello_thread.join()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello from thread <Thread(Thread-6 (hello_from_thread), started 139685613672192)>!\nPython is currently running 8 thread(s)\nThe current thread is MainThread\n```\n:::\n:::\n\n\n# And all hell broke loose: the GIL\n\n## What about Python?\n\n::::::: incremental\n\n- Designed for *sequential and single-core architecture* from the beginning\n- Everything is *interpreted* \n- All dynamic (no static types)\n\n:::::::\n\n## The GIL\n\nAka *Global Interpreter Lock*\n\n. . .\n\n- The GIL *allows* thread usage, you can create threads and launch them: YES! \n\n. . .\n\n- but...\n\n. . .\n\n- Only ONE thread can actually execute code at python level..\n\n![](./figs/nooo.jpg){ .notransparent .noinvert fig-align=\"center\" height=40%}\n\n## Multi-threaded != Parallel execution\n\nMulti-threading doesn't guarantee parallel executien...\n\n::: {.content-visible when-format=\"pdf\"}\n\\centering\n\\animategraphics[loop,width=8cm]{10}{./figs/gilbreakdance/gilbreakdance-}{0}{252}\n:::\n\n::: {.content-visible when-format=\"html\"}\n![](./figs/gilbreakdance.gif){ .notransparent .noinvert fig-align=\"center\" width=60% }\n:::\n\n$\\Longrightarrow$ Python seems to have started off with the wrong foot by a long way...\n\n## High performance Python ðŸ˜¬\n\n:::::::::::::: {.columns}\n::: {.column width=\"40%\"}\n\n::: {}\n![](figs/slow.png){ .notransparent .noinvert }\n:::\n\n:::\n::: {.column width=\"60%\"}\nBut wait!\n\n::::::: incremental\n\n1. Actually we can run (real) parallel programs with the `multiprocessing` package. \n\n    $\\Rightarrow$ But this is an \"OS level\" multiprocessing, with associated huge overhead (relatively)\n\n2. Python actually releases the GIL when executing everything that is not Python code (e.g. C/C++ extensions and libraries)\n\n    $\\Rightarrow$ It means we can parallelize our code by using I/O bound and CPU bound libraries that release the GIL (***this is the case for most of them***)\n\n:::::::\n:::\n::::::::::::::\n\n# Single-threaded asynchronous programming with `asyncio`\n\n## Socket\n\n![Writing bytes to a socket and reading bytes from a socket](figs/socket.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n- This a mailbox metaphor\n- By default, the socket is blocking, i.e. the program will wait until the socket is ready to be read or written.\n- We can make the socket non-blocking, i.e. the program will not wait for the socket to be ready to be read or written.\n    $\\Rightarrow$ Later on, the OS will tell us we received byte and we deal with it.\n\n## Socket (2)\n\n::: {.columns}\n:::: {.column width=50%}\n![](figs/socket-wait.png){ .margin-a}\n::::\n\n:::: {.column width=50%}\n::::: incremental\n- Making a non-blocking I/O request returns immediately \n- tells the O/S to watch sockets for data\n    $\\Rightarrow$ This allows execute_other_code() to run right away instead of waiting for the I/O requests to finish\n- Later, we can be alerted when I/O is complete and process the response.\n:::::\n::::\n:::\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n\n## Event Loop\n\n::: {.columns}\n:::: {.column width=50%}\n```python\nfrom collections import deque\n \nmessages = deque()\n \nwhile True:\n    if messages:\n        message = messages.pop()\n        process_message(message)\n```\n::::\n\n:::: {.column width=50%}\n::::: incremental\n- The event loop is a loop that runs forever.\n- It checks if there are any messages to process.\n- If there are, it processes them.\n- If there are not, it waits for messages to arrive.\n:::::\n::::\n:::\n\n$\\Rightarrow$ **In `asyncio`, the event loop is queue of tasks instead of messages, Tasks are wrapped coroutines.**\n\n## Event Loop (2)\n\n![](figs/event-loop.png)\n\n## Event Loop (3)\n\n```python\ndef make_request():\n    cpu_bound_setup()\n    io_bound_web_request()\n    cpu_bound_postprocess()\n \ntask_one = make_request()\ntask_two = make_request()\ntask_three = make_request()\n```\n\n## Event Loop (4)\n\n![](figs/event-loop-applied.png)\n\n# `asyncio` Coroutines\n\nTo define a coroutine, we use the `async def` syntax.\n\n```python\nasync def my_coroutine() -> None\n    print('Hello world!')\n```\n\n## What is it?\n\n::: {#3530c921 .cell output-location='column-fragment' execution_count=5}\n``` {.python .cell-code}\nasync def coroutine_add_one(number: int) -> int:\n    return number + 1\n \ndef add_one(number: int) -> int:\n    return number + 1\n \nfunction_result = add_one(1)  #<1>\ncoroutine_result = coroutine_add_one(1) #<2>\n \nprint(f'Function result is {function_result}\\n\\\n    and the type is {type(function_result)}')\nprint(f'Coroutine result is {coroutine_result}\\n\\\n    and the type is {type(coroutine_result)}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFunction result is 2\n    and the type is <class 'int'>\nCoroutine result is <coroutine object coroutine_add_one at 0x7f0afc9c1a80>\n    and the type is <class 'coroutine'>\n```\n:::\n:::\n\n\n1. function call, is executed immediately.\n2. coroutine call, is not executed at all, but returns a coroutine object.\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## How to execute a coroutine?\n\nYou need an event loop. \n\n```python\nimport asyncio\n \nasync def coroutine_add_one(number: int) -> int:\n    return number + 1\n \nresult = asyncio.run(coroutine_add_one(1)) #<1>\n\nprint(result)\n```\n1. This launches the event loop, executes the coroutine, and returns the result.\n\n## How to execute a coroutine? (2)\n\n:::{.callout-warning}\nThis code will not work in a Jupyter notebook, because the event loop is already running (by Jupyter itself). So you just have to replace the line 4 by:\n\n```python\nresult = await coroutine_add_one(1)\n```\n:::\n\n## `await` keyword\n\n::: {#80bb6852 .cell output-location='column-fragment' execution_count=6}\n``` {.python .cell-code}\nimport asyncio\n \nasync def add_one(number: int) -> int:\n    return number + 1\n \n \nasync def main() -> None:\n    one_plus_one = await add_one(1) #<1>\n    two_plus_one = await add_one(2) #<2>\n    print(one_plus_one)\n    print(two_plus_one)\n \nawait main() #<3>\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2\n3\n```\n:::\n:::\n\n\n1. Pause, and wait for the result of `add_one(1)`.\n2. Pause, and wait for the result of `add_one(2)`.\n3. Pause, and wait for the result of `main()`. (outside of a Jupyter notebook, you have to launch the event loop somewhere, like `asyncio.run(main())` instead of `await main()`)\n\n## `await` keyword (2)\n\n![](figs/await.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Simulating the real thing with `asyncio.sleep`\n\n::: {#568f73f1 .cell output-location='fragment' execution_count=7}\n``` {.python .cell-code}\nimport asyncio\n \nasync def hello_world_message() -> str:\n    await asyncio.sleep(1) #<1>\n    return 'Hello World!'\n \nasync def main() -> None:\n    message = await hello_world_message() #<2>\n    print(message)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello World!\n```\n:::\n:::\n\n\n1. Pause `hello_world_message` for 1 second.\n2. Pause `main` until `hello_world_message` is finished.\n\n## Utility function `delay(seconds)`\n\n::: {#02bcb2e6 .cell execution_count=8}\n``` {.python .cell-code}\nimport asyncio\n \n \nasync def delay(delay_seconds: int) -> int: #<1>\n    print(f'sleeping for {delay_seconds} second(s)') #<2>\n    await asyncio.sleep(delay_seconds) #<1>\n    print(f'finished sleeping for {delay_seconds} second(s)') #<2>\n    return delay_seconds #<3>\n```\n:::\n\n\n1. Takes an integer of the duration in seconds that weâ€™d like the function to sleep.\n2. Prints when sleep begins and ends.\n3. Returns that integer to the caller once it has finished sleeping.\n\n## Running two coroutines\n\n::: {#5809ab9f .cell output-location='fragment' execution_count=9}\n``` {.python .cell-code}\nimport asyncio\n \nasync def add_one(number: int) -> int:\n    return number + 1\n \nasync def hello_world_message() -> str:\n    await delay(1)\n    return 'Hello World!'\n \nasync def main() -> None:\n    message = await hello_world_message() #<1>\n    one_plus_one = await add_one(1) #<2>\n    print(one_plus_one)\n    print(message)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 1 second(s)\nfinished sleeping for 1 second(s)\n2\nHello World!\n```\n:::\n:::\n\n\n1. Pause `main` until `hello_world_message` is finished.\n2. Pause `main` until `add_one` is finished.\n\n## Running two coroutines (2)\n\n![](figs/await-2.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## What to do next?\n\nMoving away from sequential execution and run `add_one` and `hello_world_message` *concurrently*.\n\nFor that we needâ€¦\n\n# Tasks\n\nSo far we just learned how to create coroutines and put then in the event loop.\n\n**Tasks** are a way to schedule coroutines concurrently.\n\n$\\Rightarrow$ Tasks are wrapped coroutines which are scheduled to run in the event loop as soon as possible.\n\n## Creating tasks\n\n::: {#ec4546f9 .cell output-location='fragment' execution_count=10}\n``` {.python .cell-code}\nimport asyncio\n\nasync def main():\n    sleep_for_three = asyncio.create_task(delay(3))\n    print(type(sleep_for_three))\n    result = await sleep_for_three\n    print(result)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class '_asyncio.Task'>\nsleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n3\n```\n:::\n:::\n\n\n- the coroutine is scheduled to run in the event loop as soon as possible.\n- before, it was just run at the await statement (pausing the caller).\n\n## Running tasks concurrently\n\n::: {#6f94b8a3 .cell output-location='fragment' execution_count=11}\n``` {.python .cell-code}\nimport asyncio\n \nasync def main():\n    sleep_for_three = \\\n        asyncio.create_task(delay(3))\n    sleep_again = \\\n        asyncio.create_task(delay(3))\n    sleep_once_more = \\\n        asyncio.create_task(delay(3))\n \n    await sleep_for_three\n    await sleep_again\n    await sleep_once_more\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n```\n:::\n:::\n\n\n## Running tasks concurrently (2)\n\n![](figs/tasks.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Running tasks concurrently (3)\n\n::: {#dd61994b .cell output-location='fragment' execution_count=12}\n``` {.python .cell-code}\nimport asyncio\n \nasync def hello_every_second():\n    for i in range(2):\n        await asyncio.sleep(1)\n        print(\"I'm running other code while I'm waiting!\")\n \nasync def main():\n    first_delay = asyncio.create_task(delay(3))\n    second_delay = asyncio.create_task(delay(3))\n    await hello_every_second()\n    await first_delay\n    await second_delay\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nI'm running other code while I'm waiting!\nI'm running other code while I'm waiting!\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n```\n:::\n:::\n\n\n## Running tasks concurrently (4)\n\n![](figs/tasks-2.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Canceling tasks\n\n::: {#35eab67e .cell output-location='fragment' execution_count=13}\n``` {.python .cell-code}\nimport asyncio\nfrom asyncio import CancelledError\n\nasync def main():\n    long_task = asyncio.create_task(delay(10))\n \n    seconds_elapsed = 0\n \n    while not long_task.done():\n        print('Task not finished, checking again in a second.')\n        await asyncio.sleep(1)\n        seconds_elapsed = seconds_elapsed + 1\n        if seconds_elapsed == 5:\n            long_task.cancel()\n \n    try:\n        await long_task\n    except CancelledError:\n        print('Our task was cancelled')\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTask not finished, checking again in a second.\nsleeping for 10 second(s)\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nOur task was cancelled\n```\n:::\n:::\n\n\n## Setting a timeout\n\n::: {#41478b55 .cell output-location='fragment' execution_count=14}\n``` {.python .cell-code}\nimport asyncio\n\nasync def main():\n    delay_task = asyncio.create_task(delay(2))\n    try:\n        result = await asyncio.wait_for(delay_task, timeout=1)\n        print(result)\n    except asyncio.exceptions.TimeoutError:\n        print('Got a timeout!')\n        print(f'Was the task cancelled? {delay_task.cancelled()}')\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 2 second(s)\nGot a timeout!\nWas the task cancelled? True\n```\n:::\n:::\n\n\n# Tasks, coroutines, futures, and awaitables\n\n## Introducing futures\n\n::: {#bc487b2f .cell output-location='fragment' execution_count=15}\n``` {.python .cell-code}\nfrom asyncio import Future\n \nmy_future = Future()\n \nprint(f'Is my_future done? {my_future.done()}')\n \nmy_future.set_result(42)\n \nprint(f'Is my_future done? {my_future.done()}')\nprint(f'What is the result of my_future? {my_future.result()}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIs my_future done? False\nIs my_future done? True\nWhat is the result of my_future? 42\n```\n:::\n:::\n\n\n## Awaiting futures\n\n::: {#da83b95a .cell output-location='column-fragment' execution_count=16}\n``` {.python .cell-code}\nfrom asyncio import Future\nimport asyncio\n \n \ndef make_request() -> Future:\n    future = Future()\n    asyncio.create_task(set_future_value(future)) #<1>\n    return future\n \n \nasync def set_future_value(future) -> None:\n    await asyncio.sleep(1) #<2>\n    future.set_result(42)\n \n \nasync def main():\n    future = make_request()\n    print(f'Is the future done? {future.done()}')\n    value = await future #<3>\n    print(f'Is the future done? {future.done()}')\n    print(value)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIs the future done? False\nIs the future done? True\n42\n```\n:::\n:::\n\n\n1. Create a task to asynchronously set the value of the future.\n2. Wait 1 second before setting the value of the future.\n3. Pause main until the futureâ€™s value is set.\n\n## Comparing tasks, coroutines, futures, and awaitables\n\n:::{.columns} \n:::: {.column width=40%}\n<!---\n ```{.d2 sketch=true pad=0 width=400}\nAwaitable -> Coroutine\nAwaitable -> Future -> Task\nstyle: {\n    fill: \"transparent\"\n}\n```  \n--->\n![](figs/tasks-coroutines-futures-awaitables.png)\n::::\n\n:::: {.column width=60%}\n::::: incremental\nAwaitables\n: Objects that can be awaited in an async function, including coroutines, tasks, and futures.\n\nCoroutines\n: Special functions that can be paused and resumed later, defined using `async def`, and can be awaited to allow other coroutines to run.\n\nFutures\n: Represent the result of an asynchronous operation, manage its state, and can be awaited to get the result.\n\nTasks\n: Schedule and run coroutines concurrently, and can be used to cancel or check their status.\n:::::\n::::\n:::\n\n# Benchmarking\n\n## With a decorator\n\n:::{.columns}\n:::: {.column width=60%}\n\n::: {#250c548f .cell execution_count=17}\n``` {.python .cell-code}\nimport functools\nimport time\nfrom typing import Callable, Any\n \ndef async_timed():\n    def wrapper(func: Callable) -> Callable:\n        @functools.wraps(func)\n        async def wrapped(*args, **kwargs) -> Any:\n            print(f'starting {func} with args {args} {kwargs}')\n            start = time.time()\n            try:\n                return await func(*args, **kwargs)\n            finally:\n                end = time.time()\n                total = end - start\n                print(f'finished {func} in {total:.4f} second(s)')\n \n        return wrapped\n \n    return wrapper\n```\n:::\n\n\n::::\n\n:::: {.column width=40%}\n[Official Python documentation for decorators](https://peps.python.org/pep-0318/)\n\n- add functionality to an existing function\n- without modifying the function itself\n- it intercepts the function call and runs â€œdecoratedâ€ code before and after it\n::::\n:::\n\n## Using it\n\n::: {#65e0a1ca .cell output-location='column-fragment' execution_count=18}\n``` {.python .cell-code}\nimport asyncio\n \n@async_timed()\nasync def delay(delay_seconds: int) -> int:\n    print(f'sleeping for {delay_seconds} second(s)')\n    await asyncio.sleep(delay_seconds)\n    print(f'finished sleeping for {delay_seconds} second(s)')\n    return delay_seconds\n \n \n@async_timed()\nasync def main():\n    task_one = asyncio.create_task(delay(2))\n    task_two = asyncio.create_task(delay(3))\n \n    await task_one\n    await task_two\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b593465c0> with args () {}\nstarting <function delay at 0x7f0b59345e40> with args (2,) {}\nsleeping for 2 second(s)\nstarting <function delay at 0x7f0b59345e40> with args (3,) {}\nsleeping for 3 second(s)\nfinished sleeping for 2 second(s)\nfinished <function delay at 0x7f0b59345e40> in 2.0021 second(s)\nfinished sleeping for 3 second(s)\nfinished <function delay at 0x7f0b59345e40> in 3.0011 second(s)\nfinished <function main at 0x7f0b593465c0> in 3.0013 second(s)\n```\n:::\n:::\n\n\n## `asyncio.gather`\n\nasyncio.gather() runs multiple asynchronous operations, wraps a coroutine as a task, and returns a list of results in the same order of awaitables.\n\n::: {#ec37f683 .cell output-location='column-fragment' execution_count=19}\n``` {.python .cell-code}\nimport asyncio\n\n\nasync def call_api(message, result, delay=3):\n    print(message)\n    await asyncio.sleep(delay)\n    return result\n\n\nasync def main():\n    return await asyncio.gather(\n        call_api('Calling API 1 ...', 1),\n        call_api('Calling API 2 ...', 2)\n    )\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCalling API 1 ...\nCalling API 2 ...\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n[1, 2]\n```\n:::\n:::\n\n\n## `asyncio.gather` (2)\n\n:::{ .callout-caution}\n`asyncio.gather` takes a tuple of awaitables, not a list of awaitables, but returns a list of results in the same order of awaitables.\n\nIf you want to pass a list, use the `*` operator to unpack it as a tuple.\n:::\n\n\n# Pitfalls of asynchronous programming\n\n## Running CPU-bound code\n\n::: {#a2323a09 .cell output-location='column-fragment' execution_count=20}\n``` {.python .cell-code}\nimport asyncio\n\n@async_timed()\nasync def cpu_bound_work() -> int:\n    counter = 0\n    for i in range(100000000):\n        counter = counter + 1\n    return counter\n \n \n@async_timed()\nasync def main():\n    task_one = asyncio.create_task(cpu_bound_work())\n    task_two = asyncio.create_task(cpu_bound_work())\n    await task_one\n    await task_two\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b59346ac0> with args () {}\nstarting <function cpu_bound_work at 0x7f0b593468e0> with args () {}\nfinished <function cpu_bound_work at 0x7f0b593468e0> in 4.1800 second(s)\nstarting <function cpu_bound_work at 0x7f0b593468e0> with args () {}\nfinished <function cpu_bound_work at 0x7f0b593468e0> in 4.1962 second(s)\nfinished <function main at 0x7f0b59346ac0> in 8.3767 second(s)\n```\n:::\n:::\n\n\n## Running blocking APIs\n\n::: {#0be21322 .cell output-location='column-fragment' execution_count=21}\n``` {.python .cell-code}\nimport asyncio\nimport requests\n \n@async_timed()\nasync def get_example_status() -> int:\n    return requests.get('http://www.example.com').status_code\n \n \n@async_timed()\nasync def main():\n    task_1 = asyncio.create_task(get_example_status())\n    task_2 = asyncio.create_task(get_example_status())\n    task_3 = asyncio.create_task(get_example_status())\n    await task_1\n    await task_2\n    await task_3\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b586cafc0> with args () {}\nstarting <function get_example_status at 0x7f0b59323ec0> with args () {}\nfinished <function get_example_status at 0x7f0b59323ec0> in 0.3124 second(s)\nstarting <function get_example_status at 0x7f0b59323ec0> with args () {}\nfinished <function get_example_status at 0x7f0b59323ec0> in 0.1888 second(s)\nstarting <function get_example_status at 0x7f0b59323ec0> with args () {}\nfinished <function get_example_status at 0x7f0b59323ec0> in 0.1788 second(s)\nfinished <function main at 0x7f0b586cafc0> in 0.6803 second(s)\n```\n:::\n:::\n\n\n# Asynchronous threading\n\n\n## Example of blocking code\n\n::: {#e31b8a0a .cell output-location='column-fragment' execution_count=22}\n``` {.python .cell-code}\nimport requests\n \n \ndef get_status_code(url: str) -> int:\n    response = requests.get(url)\n    return response.status_code\n \n \nurl = 'https://www.example.com'\nprint(get_status_code(url))\nprint(get_status_code(url))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n200\n200\n```\n:::\n:::\n\n\n## Thread Pool\n\n::: {#e0e80006 .cell output-location='fragment' execution_count=23}\n``` {.python .cell-code}\nimport time\nimport requests\nfrom concurrent.futures import ThreadPoolExecutor\n \n \ndef get_status_code(url: str) -> int:\n    response = requests.get(url)\n    return response.status_code\n \n \nstart = time.time()\n \nwith ThreadPoolExecutor() as pool:\n    urls = ['https://www.example.com' for _ in range(10)]\n    results = pool.map(get_status_code, urls)\n    for result in results:\n        # print(result)\n        pass\n\n \nend = time.time()\n \nprint(f'finished requests in {end - start:.4f} second(s)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfinished requests in 0.3860 second(s)\n```\n:::\n:::\n\n\n## Compare with sequential code\n\n::: {#653bef6b .cell output-location='fragment' execution_count=24}\n``` {.python .cell-code}\nstart = time.time()\n \nurls = ['https://www.example.com' for _ in range(10)]\n \nfor url in urls:\n    result = get_status_code(url)\n    # print(result)\n \nend = time.time()\n \nprint(f'finished requests in {end - start:.4f} second(s)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfinished requests in 3.6004 second(s)\n```\n:::\n:::\n\n\n## Thread pool with `asyncio`\n\n::: {#d92e0f5f .cell output-location='fragment' execution_count=25}\n``` {.python .cell-code}\nimport functools\nimport requests\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n \ndef get_status_code(url: str) -> int:\n    response = requests.get(url)\n    return response.status_code\n \n \n@async_timed()\nasync def main():\n    loop = asyncio.get_running_loop()\n    with ThreadPoolExecutor() as pool:\n        urls = ['https://www.example.com' for _ in range(10)]\n        tasks = [loop.run_in_executor(pool, functools.partial(get_status_code, url)) for url in urls]\n        results = await asyncio.gather(*tasks)\n        print(results)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b5871bd80> with args () {}\n[200, 200, 200, 200, 200, 200, 200, 200, 200, 200]\nfinished <function main at 0x7f0b5871bd80> in 0.3865 second(s)\n```\n:::\n:::\n\n\n## Multithreading with numpy\n\nLetâ€™s define a big matrix on which we will compute the mean of each row.\n\n\n\n## Multithreading with numpy (2)\n\nNow process the matrix sequentially.\n\n::: {#7e365ab2 .cell output-location='fragment' execution_count=27}\n``` {.python .cell-code}\ns = time.time()\n \nres_seq = np.mean(matrix, axis=1)\n \ne = time.time()\nprint(e - s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.47089385986328125\n```\n:::\n:::\n\n\n## Multithreading with numpy (3)\n\nAnd then the same with multithreading (we check that the results are *exactly* the same).\n\n::: {#2d6b7471 .cell output-location='fragment' execution_count=28}\n``` {.python .cell-code}\nimport functools\nfrom concurrent.futures.thread import ThreadPoolExecutor\nimport asyncio\n \ndef mean_for_row(arr, row):\n    return np.mean(arr[row])\n \n@async_timed()\nasync def main():\n    loop = asyncio.get_running_loop()\n    with ThreadPoolExecutor() as pool:\n        tasks = []\n        for i in range(rows):\n            mean = functools.partial(mean_for_row, matrix, i)\n            tasks.append(loop.run_in_executor(pool, mean))\n \n        return await asyncio.gather(*tasks)\n\nres_threads = np.array(await main())\nnp.testing.assert_array_equal(res_seq, res_threads)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b5871b9c0> with args () {}\nfinished <function main at 0x7f0b5871b9c0> in 0.0771 second(s)\n```\n:::\n:::\n\n\n# Conclusion\n\n::::: incremental\n- Everything is `awaitable` (coroutines, futures, tasks), i.e. can be simply run with `await`.\n- a task is a coroutine wrapped in a future, and scheduled to run in the event loop.\n- `asyncio` is a single-threaded asynchronous programming library, providing a simple way to write concurrent code for I/O bound tasks.\n\n    $\\Rightarrow$ Weâ€™ll see later that this programming model can be used for parallelism as well, and very easily.\n:::::\n\n# References {.allowframebreaks}\n\n",
    "supporting": [
      "3_Asynchronous_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}