{
  "hash": "ce5e97914718655422eae041319b6a74",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Asynchronous Programming with Python\nsubtitle: One programming model to rule them all\nnocite: |\n    @fowler2022python\n---\n\n\n# Asynchronous, Basics\n\n## What is Asynchronous Programming?\n\n- Asynchronous programming is a programming paradigm that allows the program to continue executing other tasks before the current task is finished.\n- It is a way to achieve concurrency in a program.\n\n$\\Rightarrow$  it is an **abstraction over concurrency**, it does not necessarily mean that the program is executed in parallel.\n\n## I/O Bound vs. CPU Bound\n\n```python\nimport requests\n \nresponse = requests.get('https://www.example.com')      #<1>\n \nitems = response.headers.items()\n \nheaders = [f'{key}: {header}' for key, header in items] #<2>\n \nformatted_headers = '\\n'.join(headers)                  #<3>\n \nwith open('headers.txt', 'w') as file:\n    file.write(formatted_headers)                       #<4>\n```\n1. I/O-bound web request\n2. CPU-bound response processing\n3. CPU-bound string concatenation\n4. I/O-bound write to disk\n\n# Concurrency, parallelism and multitasking\n\nWe will use extensively the bakery metaphor.\n\n\n## Concurrency vs. Parallelism\n\n::: {.columns}\n:::: {.column width=50%}\nOne baker and two cakes to prepare.\n\n- Can preheat the oven while preparing the first cake.\n- Can start the second cake while the first one is in the oven.\n\n$\\Rightarrow$ **Switching between tasks** is **concurrency** (or concurrent behavior).\n::::\n\n:::: {.column width=50%}\nTwo bakers and two cakes to prepare.\n\n- Can prepare both cakes at the same time.\n\n$\\Rightarrow$ **Doing multiple tasks in parallel** is **parallelism** (or parallel behavior).\n::::\n:::\n\n## Concurrency vs. Parallelism (2)\n\n![With concurrency, we have multiple tasks happening at the same time, but only one we’re actively doing at a given point in time. With parallelism, we have multiple tasks happening and are actively doing more than one simultaneously.](d2-figures/bakers.svg)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Concurrency vs. Parallelism (3)\n\n![With concurrency, we switch between running two applications. With parallelism, we actively run two applications simultaneously.](d2-figures/concurrency.svg)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Concurrency vs. Parallelism (4)\n\n- Concurrency is about multiple **independent** tasks that can happen.\n- Parallelism is concurrency AND **simultaneous** execution.\n\nWhile parallelism implies concurrency, concurrency does not always imply parallelism.\n\n$\\Rightarrow$ Concurrency is a **broader** concept than parallelism.\n\n## Multitasking\n\n::: {.columns}\n:::: {.column width=50%}\n### Preemptive multitasking\n\n- The operating system decides when to switch between tasks.\n- The tasks are not aware of each other.\n\n::::\n\n:::: {.column width=50%}\n### Cooperative multitasking\n\n- In this model we have to explicitly to decide when to switch between tasks.\n- The tasks are aware of each other.\n\n::::\n:::\n\n## Benefits of cooperative multitasking\n\n- Less overhead than preemptive multitasking.\n- Granular/optimal control over when to switch between tasks.\n\n# Processes, threads, multithreading, and multiprocessing\n\n## Multi-processing vs Multi-threading \n\n:::{layout-ncol=\"2\"}\n\n![Multi-Processing](tikz-figures/multiprocessing_model.svg)\n\n![Multi-Threading](tikz-figures/multithreading_model.svg)\n\n:::\n\n## Processes and threads\n\n::: {#c5a1a7ea .cell output-location='fragment' execution_count=2}\n``` {.python .cell-code lst-cap=\"Processes and threads in a simple Python application\"}\nimport os\nimport threading\n \nprint(f'Python process running with process id: {os.getpid()}')\ntotal_threads = threading.active_count()\nthread_name = threading.current_thread().name\n \nprint(f'Python is currently running {total_threads} thread(s)')\nprint(f'The current thread is {thread_name}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPython process running with process id: 119943\nPython is currently running 8 thread(s)\nThe current thread is MainThread\n```\n:::\n:::\n\n\n## Creating processes\n\n::: {#245a2049 .cell output-location='fragment' execution_count=3}\n``` {.python .cell-code lst-cap=\"Creating processes in Python\"}\nimport multiprocessing\nimport os\n \n \ndef hello_from_process():\n    print(f'Hello from child process {os.getpid()}!')\nif __name__ == '__main__':\n    hello_process = multiprocessing.Process(target=hello_from_process)\n    hello_process.start()\n \n    print(f'Hello from parent process {os.getpid()}')\n \n    hello_process.join()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello from child process 119972!\nHello from parent process 119943\n```\n:::\n:::\n\n\n## Creating threads\n\n::: {#6ba8679a .cell output-location='fragment' execution_count=4}\n``` {.python .cell-code lst-cap=\"Creating threads in Python\"}\nimport threading\n \n \ndef hello_from_thread():\n    print(f'Hello from thread {threading.current_thread()}!')\n \n \nhello_thread = threading.Thread(target=hello_from_thread)\nhello_thread.start()\n \ntotal_threads = threading.active_count()\nthread_name = threading.current_thread().name\n \nprint(f'Python is currently running {total_threads} thread(s)')\nprint(f'The current thread is {thread_name}')\n \nhello_thread.join()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello from thread <Thread(Thread-6 (hello_from_thread), started 139685613672192)>!\nPython is currently running 8 thread(s)\nThe current thread is MainThread\n```\n:::\n:::\n\n\n# And all hell broke loose: the GIL\n\n## What about Python?\n\n::::::: incremental\n\n- Designed for *sequential and single-core architecture* from the beginning\n- Everything is *interpreted* \n- All dynamic (no static types)\n\n:::::::\n\n## The GIL\n\nAka *Global Interpreter Lock*\n\n. . .\n\n- The GIL *allows* thread usage, you can create threads and launch them: YES! \n\n. . .\n\n- but...\n\n. . .\n\n- Only ONE thread can actually execute code at python level..\n\n![](./figs/nooo.jpg){ .notransparent .noinvert fig-align=\"center\" height=40%}\n\n## Multi-threaded != Parallel execution\n\nMulti-threading doesn't guarantee parallel executien...\n\n::: {.content-visible when-format=\"pdf\"}\n\\centering\n\\animategraphics[loop,width=8cm]{10}{./figs/gilbreakdance/gilbreakdance-}{0}{252}\n:::\n\n::: {.content-visible when-format=\"html\"}\n![](./figs/gilbreakdance.gif){ .notransparent .noinvert fig-align=\"center\" width=60% }\n:::\n\n$\\Longrightarrow$ Python seems to have started off with the wrong foot by a long way...\n\n## High performance Python 😬\n\n:::::::::::::: {.columns}\n::: {.column width=\"40%\"}\n\n::: {}\n![](figs/slow.png){ .notransparent .noinvert }\n:::\n\n:::\n::: {.column width=\"60%\"}\nBut wait!\n\n::::::: incremental\n\n1. Actually we can run (real) parallel programs with the `multiprocessing` package. \n\n    $\\Rightarrow$ But this is an \"OS level\" multiprocessing, with associated huge overhead (relatively)\n\n2. Python actually releases the GIL when executing everything that is not Python code (e.g. C/C++ extensions and libraries)\n\n    $\\Rightarrow$ It means we can parallelize our code by using I/O bound and CPU bound libraries that release the GIL (***this is the case for most of them***)\n\n:::::::\n:::\n::::::::::::::\n\n# Single-threaded asynchronous programming with `asyncio`\n\n## Socket\n\n![Writing bytes to a socket and reading bytes from a socket](figs/socket.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n- This a mailbox metaphor\n- By default, the socket is blocking, i.e. the program will wait until the socket is ready to be read or written.\n- We can make the socket non-blocking, i.e. the program will not wait for the socket to be ready to be read or written.\n    $\\Rightarrow$ Later on, the OS will tell us we received byte and we deal with it.\n\n## Socket (2)\n\n::: {.columns}\n:::: {.column width=50%}\n![](figs/socket-wait.png){ .margin-a}\n::::\n\n:::: {.column width=50%}\n::::: incremental\n- Making a non-blocking I/O request returns immediately \n- tells the O/S to watch sockets for data\n    $\\Rightarrow$ This allows execute_other_code() to run right away instead of waiting for the I/O requests to finish\n- Later, we can be alerted when I/O is complete and process the response.\n:::::\n::::\n:::\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n\n## Event Loop\n\n::: {.columns}\n:::: {.column width=50%}\n```python\nfrom collections import deque\n \nmessages = deque()\n \nwhile True:\n    if messages:\n        message = messages.pop()\n        process_message(message)\n```\n::::\n\n:::: {.column width=50%}\n::::: incremental\n- The event loop is a loop that runs forever.\n- It checks if there are any messages to process.\n- If there are, it processes them.\n- If there are not, it waits for messages to arrive.\n:::::\n::::\n:::\n\n$\\Rightarrow$ **In `asyncio`, the event loop is queue of tasks instead of messages, Tasks are wrapped coroutines.**\n\n## Event Loop (2)\n\n![](figs/event-loop.png)\n\n## Event Loop (3)\n\n```python\ndef make_request():\n    cpu_bound_setup()\n    io_bound_web_request()\n    cpu_bound_postprocess()\n \ntask_one = make_request()\ntask_two = make_request()\ntask_three = make_request()\n```\n\n## Event Loop (4)\n\n![](figs/event-loop-applied.png)\n\n# `asyncio` Coroutines\n\nTo define a coroutine, we use the `async def` syntax.\n\n```python\nasync def my_coroutine() -> None\n    print('Hello world!')\n```\n\n## What is it?\n\n::: {#3530c921 .cell output-location='column-fragment' execution_count=5}\n``` {.python .cell-code}\nasync def coroutine_add_one(number: int) -> int:\n    return number + 1\n \ndef add_one(number: int) -> int:\n    return number + 1\n \nfunction_result = add_one(1)  #<1>\ncoroutine_result = coroutine_add_one(1) #<2>\n \nprint(f'Function result is {function_result}\\n\\\n    and the type is {type(function_result)}')\nprint(f'Coroutine result is {coroutine_result}\\n\\\n    and the type is {type(coroutine_result)}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFunction result is 2\n    and the type is <class 'int'>\nCoroutine result is <coroutine object coroutine_add_one at 0x7f0afc9c1a80>\n    and the type is <class 'coroutine'>\n```\n:::\n:::\n\n\n1. function call, is executed immediately.\n2. coroutine call, is not executed at all, but returns a coroutine object.\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## How to execute a coroutine?\n\nYou need an event loop. \n\n```python\nimport asyncio\n \nasync def coroutine_add_one(number: int) -> int:\n    return number + 1\n \nresult = asyncio.run(coroutine_add_one(1)) #<1>\n\nprint(result)\n```\n1. This launches the event loop, executes the coroutine, and returns the result.\n\n## How to execute a coroutine? (2)\n\n:::{.callout-warning}\nThis code will not work in a Jupyter notebook, because the event loop is already running (by Jupyter itself). So you just have to replace the line 4 by:\n\n```python\nresult = await coroutine_add_one(1)\n```\n:::\n\n## `await` keyword\n\n::: {#80bb6852 .cell output-location='column-fragment' execution_count=6}\n``` {.python .cell-code}\nimport asyncio\n \nasync def add_one(number: int) -> int:\n    return number + 1\n \n \nasync def main() -> None:\n    one_plus_one = await add_one(1) #<1>\n    two_plus_one = await add_one(2) #<2>\n    print(one_plus_one)\n    print(two_plus_one)\n \nawait main() #<3>\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2\n3\n```\n:::\n:::\n\n\n1. Pause, and wait for the result of `add_one(1)`.\n2. Pause, and wait for the result of `add_one(2)`.\n3. Pause, and wait for the result of `main()`. (outside of a Jupyter notebook, you have to launch the event loop somewhere, like `asyncio.run(main())` instead of `await main()`)\n\n## `await` keyword (2)\n\n![](figs/await.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Simulating the real thing with `asyncio.sleep`\n\n::: {#568f73f1 .cell output-location='fragment' execution_count=7}\n``` {.python .cell-code}\nimport asyncio\n \nasync def hello_world_message() -> str:\n    await asyncio.sleep(1) #<1>\n    return 'Hello World!'\n \nasync def main() -> None:\n    message = await hello_world_message() #<2>\n    print(message)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHello World!\n```\n:::\n:::\n\n\n1. Pause `hello_world_message` for 1 second.\n2. Pause `main` until `hello_world_message` is finished.\n\n## Utility function `delay(seconds)`\n\n::: {#02bcb2e6 .cell execution_count=8}\n``` {.python .cell-code}\nimport asyncio\n \n \nasync def delay(delay_seconds: int) -> int: #<1>\n    print(f'sleeping for {delay_seconds} second(s)') #<2>\n    await asyncio.sleep(delay_seconds) #<1>\n    print(f'finished sleeping for {delay_seconds} second(s)') #<2>\n    return delay_seconds #<3>\n```\n:::\n\n\n1. Takes an integer of the duration in seconds that we’d like the function to sleep.\n2. Prints when sleep begins and ends.\n3. Returns that integer to the caller once it has finished sleeping.\n\n## Running two coroutines\n\n::: {#5809ab9f .cell output-location='fragment' execution_count=9}\n``` {.python .cell-code}\nimport asyncio\n \nasync def add_one(number: int) -> int:\n    return number + 1\n \nasync def hello_world_message() -> str:\n    await delay(1)\n    return 'Hello World!'\n \nasync def main() -> None:\n    message = await hello_world_message() #<1>\n    one_plus_one = await add_one(1) #<2>\n    print(one_plus_one)\n    print(message)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 1 second(s)\nfinished sleeping for 1 second(s)\n2\nHello World!\n```\n:::\n:::\n\n\n1. Pause `main` until `hello_world_message` is finished.\n2. Pause `main` until `add_one` is finished.\n\n## Running two coroutines (2)\n\n![](figs/await-2.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## What to do next?\n\nMoving away from sequential execution and run `add_one` and `hello_world_message` *concurrently*.\n\nFor that we need…\n\n# Tasks\n\nSo far we just learned how to create coroutines and put then in the event loop.\n\n**Tasks** are a way to schedule coroutines concurrently.\n\n$\\Rightarrow$ Tasks are wrapped coroutines which are scheduled to run in the event loop as soon as possible.\n\n## Creating tasks\n\n::: {#ec4546f9 .cell output-location='fragment' execution_count=10}\n``` {.python .cell-code}\nimport asyncio\n\nasync def main():\n    sleep_for_three = asyncio.create_task(delay(3))\n    print(type(sleep_for_three))\n    result = await sleep_for_three\n    print(result)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class '_asyncio.Task'>\nsleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n3\n```\n:::\n:::\n\n\n- the coroutine is scheduled to run in the event loop as soon as possible.\n- before, it was just run at the await statement (pausing the caller).\n\n## Running tasks concurrently\n\n::: {#6f94b8a3 .cell output-location='fragment' execution_count=11}\n``` {.python .cell-code}\nimport asyncio\n \nasync def main():\n    sleep_for_three = \\\n        asyncio.create_task(delay(3))\n    sleep_again = \\\n        asyncio.create_task(delay(3))\n    sleep_once_more = \\\n        asyncio.create_task(delay(3))\n \n    await sleep_for_three\n    await sleep_again\n    await sleep_once_more\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n```\n:::\n:::\n\n\n## Running tasks concurrently (2)\n\n![](figs/tasks.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Running tasks concurrently (3)\n\n::: {#dd61994b .cell output-location='fragment' execution_count=12}\n``` {.python .cell-code}\nimport asyncio\n \nasync def hello_every_second():\n    for i in range(2):\n        await asyncio.sleep(1)\n        print(\"I'm running other code while I'm waiting!\")\n \nasync def main():\n    first_delay = asyncio.create_task(delay(3))\n    second_delay = asyncio.create_task(delay(3))\n    await hello_every_second()\n    await first_delay\n    await second_delay\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 3 second(s)\nsleeping for 3 second(s)\nI'm running other code while I'm waiting!\nI'm running other code while I'm waiting!\nfinished sleeping for 3 second(s)\nfinished sleeping for 3 second(s)\n```\n:::\n:::\n\n\n## Running tasks concurrently (4)\n\n![](figs/tasks-2.png)\n\n:::{.attribution}\nFrom @fowler2022python\n:::\n\n## Canceling tasks\n\n::: {#35eab67e .cell output-location='fragment' execution_count=13}\n``` {.python .cell-code}\nimport asyncio\nfrom asyncio import CancelledError\n\nasync def main():\n    long_task = asyncio.create_task(delay(10))\n \n    seconds_elapsed = 0\n \n    while not long_task.done():\n        print('Task not finished, checking again in a second.')\n        await asyncio.sleep(1)\n        seconds_elapsed = seconds_elapsed + 1\n        if seconds_elapsed == 5:\n            long_task.cancel()\n \n    try:\n        await long_task\n    except CancelledError:\n        print('Our task was cancelled')\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTask not finished, checking again in a second.\nsleeping for 10 second(s)\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nTask not finished, checking again in a second.\nOur task was cancelled\n```\n:::\n:::\n\n\n## Setting a timeout\n\n::: {#41478b55 .cell output-location='fragment' execution_count=14}\n``` {.python .cell-code}\nimport asyncio\n\nasync def main():\n    delay_task = asyncio.create_task(delay(2))\n    try:\n        result = await asyncio.wait_for(delay_task, timeout=1)\n        print(result)\n    except asyncio.exceptions.TimeoutError:\n        print('Got a timeout!')\n        print(f'Was the task cancelled? {delay_task.cancelled()}')\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsleeping for 2 second(s)\nGot a timeout!\nWas the task cancelled? True\n```\n:::\n:::\n\n\n# Tasks, coroutines, futures, and awaitables\n\n## Introducing futures\n\n::: {#bc487b2f .cell output-location='fragment' execution_count=15}\n``` {.python .cell-code}\nfrom asyncio import Future\n \nmy_future = Future()\n \nprint(f'Is my_future done? {my_future.done()}')\n \nmy_future.set_result(42)\n \nprint(f'Is my_future done? {my_future.done()}')\nprint(f'What is the result of my_future? {my_future.result()}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIs my_future done? False\nIs my_future done? True\nWhat is the result of my_future? 42\n```\n:::\n:::\n\n\n## Awaiting futures\n\n::: {#da83b95a .cell output-location='column-fragment' execution_count=16}\n``` {.python .cell-code}\nfrom asyncio import Future\nimport asyncio\n \n \ndef make_request() -> Future:\n    future = Future()\n    asyncio.create_task(set_future_value(future)) #<1>\n    return future\n \n \nasync def set_future_value(future) -> None:\n    await asyncio.sleep(1) #<2>\n    future.set_result(42)\n \n \nasync def main():\n    future = make_request()\n    print(f'Is the future done? {future.done()}')\n    value = await future #<3>\n    print(f'Is the future done? {future.done()}')\n    print(value)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIs the future done? False\nIs the future done? True\n42\n```\n:::\n:::\n\n\n1. Create a task to asynchronously set the value of the future.\n2. Wait 1 second before setting the value of the future.\n3. Pause main until the future’s value is set.\n\n## Comparing tasks, coroutines, futures, and awaitables\n\n:::{.columns} \n:::: {.column width=40%}\n<!---\n ```{.d2 sketch=true pad=0 width=400}\nAwaitable -> Coroutine\nAwaitable -> Future -> Task\nstyle: {\n    fill: \"transparent\"\n}\n```  \n--->\n![](figs/tasks-coroutines-futures-awaitables.png)\n::::\n\n:::: {.column width=60%}\n::::: incremental\nAwaitables\n: Objects that can be awaited in an async function, including coroutines, tasks, and futures.\n\nCoroutines\n: Special functions that can be paused and resumed later, defined using `async def`, and can be awaited to allow other coroutines to run.\n\nFutures\n: Represent the result of an asynchronous operation, manage its state, and can be awaited to get the result.\n\nTasks\n: Schedule and run coroutines concurrently, and can be used to cancel or check their status.\n:::::\n::::\n:::\n\n# Benchmarking\n\n## With a decorator\n\n:::{.columns}\n:::: {.column width=60%}\n\n::: {#250c548f .cell execution_count=17}\n``` {.python .cell-code}\nimport functools\nimport time\nfrom typing import Callable, Any\n \ndef async_timed():\n    def wrapper(func: Callable) -> Callable:\n        @functools.wraps(func)\n        async def wrapped(*args, **kwargs) -> Any:\n            print(f'starting {func} with args {args} {kwargs}')\n            start = time.time()\n            try:\n                return await func(*args, **kwargs)\n            finally:\n                end = time.time()\n                total = end - start\n                print(f'finished {func} in {total:.4f} second(s)')\n \n        return wrapped\n \n    return wrapper\n```\n:::\n\n\n::::\n\n:::: {.column width=40%}\n[Official Python documentation for decorators](https://peps.python.org/pep-0318/)\n\n- add functionality to an existing function\n- without modifying the function itself\n- it intercepts the function call and runs “decorated” code before and after it\n::::\n:::\n\n## Using it\n\n::: {#65e0a1ca .cell output-location='column-fragment' execution_count=18}\n``` {.python .cell-code}\nimport asyncio\n \n@async_timed()\nasync def delay(delay_seconds: int) -> int:\n    print(f'sleeping for {delay_seconds} second(s)')\n    await asyncio.sleep(delay_seconds)\n    print(f'finished sleeping for {delay_seconds} second(s)')\n    return delay_seconds\n \n \n@async_timed()\nasync def main():\n    task_one = asyncio.create_task(delay(2))\n    task_two = asyncio.create_task(delay(3))\n \n    await task_one\n    await task_two\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b593465c0> with args () {}\nstarting <function delay at 0x7f0b59345e40> with args (2,) {}\nsleeping for 2 second(s)\nstarting <function delay at 0x7f0b59345e40> with args (3,) {}\nsleeping for 3 second(s)\nfinished sleeping for 2 second(s)\nfinished <function delay at 0x7f0b59345e40> in 2.0021 second(s)\nfinished sleeping for 3 second(s)\nfinished <function delay at 0x7f0b59345e40> in 3.0011 second(s)\nfinished <function main at 0x7f0b593465c0> in 3.0013 second(s)\n```\n:::\n:::\n\n\n## `asyncio.gather`\n\nasyncio.gather() runs multiple asynchronous operations, wraps a coroutine as a task, and returns a list of results in the same order of awaitables.\n\n::: {#ec37f683 .cell output-location='column-fragment' execution_count=19}\n``` {.python .cell-code}\nimport asyncio\n\n\nasync def call_api(message, result, delay=3):\n    print(message)\n    await asyncio.sleep(delay)\n    return result\n\n\nasync def main():\n    return await asyncio.gather(\n        call_api('Calling API 1 ...', 1),\n        call_api('Calling API 2 ...', 2)\n    )\n\nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCalling API 1 ...\nCalling API 2 ...\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n[1, 2]\n```\n:::\n:::\n\n\n## `asyncio.gather` (2)\n\n:::{ .callout-caution}\n`asyncio.gather` takes a tuple of awaitables, not a list of awaitables, but returns a list of results in the same order of awaitables.\n\nIf you want to pass a list, use the `*` operator to unpack it as a tuple.\n:::\n\n\n# Pitfalls of asynchronous programming\n\n## Running CPU-bound code\n\n::: {#a2323a09 .cell output-location='column-fragment' execution_count=20}\n``` {.python .cell-code}\nimport asyncio\n\n@async_timed()\nasync def cpu_bound_work() -> int:\n    counter = 0\n    for i in range(100000000):\n        counter = counter + 1\n    return counter\n \n \n@async_timed()\nasync def main():\n    task_one = asyncio.create_task(cpu_bound_work())\n    task_two = asyncio.create_task(cpu_bound_work())\n    await task_one\n    await task_two\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b59346ac0> with args () {}\nstarting <function cpu_bound_work at 0x7f0b593468e0> with args () {}\nfinished <function cpu_bound_work at 0x7f0b593468e0> in 4.1800 second(s)\nstarting <function cpu_bound_work at 0x7f0b593468e0> with args () {}\nfinished <function cpu_bound_work at 0x7f0b593468e0> in 4.1962 second(s)\nfinished <function main at 0x7f0b59346ac0> in 8.3767 second(s)\n```\n:::\n:::\n\n\n## Running blocking APIs\n\n::: {#0be21322 .cell output-location='column-fragment' execution_count=21}\n``` {.python .cell-code}\nimport asyncio\nimport requests\n \n@async_timed()\nasync def get_example_status() -> int:\n    return requests.get('http://www.example.com').status_code\n \n \n@async_timed()\nasync def main():\n    task_1 = asyncio.create_task(get_example_status())\n    task_2 = asyncio.create_task(get_example_status())\n    task_3 = asyncio.create_task(get_example_status())\n    await task_1\n    await task_2\n    await task_3\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b586cafc0> with args () {}\nstarting <function get_example_status at 0x7f0b59323ec0> with args () {}\nfinished <function get_example_status at 0x7f0b59323ec0> in 0.3124 second(s)\nstarting <function get_example_status at 0x7f0b59323ec0> with args () {}\nfinished <function get_example_status at 0x7f0b59323ec0> in 0.1888 second(s)\nstarting <function get_example_status at 0x7f0b59323ec0> with args () {}\nfinished <function get_example_status at 0x7f0b59323ec0> in 0.1788 second(s)\nfinished <function main at 0x7f0b586cafc0> in 0.6803 second(s)\n```\n:::\n:::\n\n\n# Asynchronous threading\n\n\n## Example of blocking code\n\n::: {#e31b8a0a .cell output-location='column-fragment' execution_count=22}\n``` {.python .cell-code}\nimport requests\n \n \ndef get_status_code(url: str) -> int:\n    response = requests.get(url)\n    return response.status_code\n \n \nurl = 'https://www.example.com'\nprint(get_status_code(url))\nprint(get_status_code(url))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n200\n200\n```\n:::\n:::\n\n\n## Thread Pool\n\n::: {#e0e80006 .cell output-location='fragment' execution_count=23}\n``` {.python .cell-code}\nimport time\nimport requests\nfrom concurrent.futures import ThreadPoolExecutor\n \n \ndef get_status_code(url: str) -> int:\n    response = requests.get(url)\n    return response.status_code\n \n \nstart = time.time()\n \nwith ThreadPoolExecutor() as pool:\n    urls = ['https://www.example.com' for _ in range(10)]\n    results = pool.map(get_status_code, urls)\n    for result in results:\n        # print(result)\n        pass\n\n \nend = time.time()\n \nprint(f'finished requests in {end - start:.4f} second(s)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfinished requests in 0.3860 second(s)\n```\n:::\n:::\n\n\n## Compare with sequential code\n\n::: {#653bef6b .cell output-location='fragment' execution_count=24}\n``` {.python .cell-code}\nstart = time.time()\n \nurls = ['https://www.example.com' for _ in range(10)]\n \nfor url in urls:\n    result = get_status_code(url)\n    # print(result)\n \nend = time.time()\n \nprint(f'finished requests in {end - start:.4f} second(s)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfinished requests in 3.6004 second(s)\n```\n:::\n:::\n\n\n## Thread pool with `asyncio`\n\n::: {#d92e0f5f .cell output-location='fragment' execution_count=25}\n``` {.python .cell-code}\nimport functools\nimport requests\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n \ndef get_status_code(url: str) -> int:\n    response = requests.get(url)\n    return response.status_code\n \n \n@async_timed()\nasync def main():\n    loop = asyncio.get_running_loop()\n    with ThreadPoolExecutor() as pool:\n        urls = ['https://www.example.com' for _ in range(10)]\n        tasks = [loop.run_in_executor(pool, functools.partial(get_status_code, url)) for url in urls]\n        results = await asyncio.gather(*tasks)\n        print(results)\n \nawait main()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b5871bd80> with args () {}\n[200, 200, 200, 200, 200, 200, 200, 200, 200, 200]\nfinished <function main at 0x7f0b5871bd80> in 0.3865 second(s)\n```\n:::\n:::\n\n\n## Multithreading with numpy\n\nLet’s define a big matrix on which we will compute the mean of each row.\n\n\n\n## Multithreading with numpy (2)\n\nNow process the matrix sequentially.\n\n::: {#7e365ab2 .cell output-location='fragment' execution_count=27}\n``` {.python .cell-code}\ns = time.time()\n \nres_seq = np.mean(matrix, axis=1)\n \ne = time.time()\nprint(e - s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.47089385986328125\n```\n:::\n:::\n\n\n## Multithreading with numpy (3)\n\nAnd then the same with multithreading (we check that the results are *exactly* the same).\n\n::: {#2d6b7471 .cell output-location='fragment' execution_count=28}\n``` {.python .cell-code}\nimport functools\nfrom concurrent.futures.thread import ThreadPoolExecutor\nimport asyncio\n \ndef mean_for_row(arr, row):\n    return np.mean(arr[row])\n \n@async_timed()\nasync def main():\n    loop = asyncio.get_running_loop()\n    with ThreadPoolExecutor() as pool:\n        tasks = []\n        for i in range(rows):\n            mean = functools.partial(mean_for_row, matrix, i)\n            tasks.append(loop.run_in_executor(pool, mean))\n \n        return await asyncio.gather(*tasks)\n\nres_threads = np.array(await main())\nnp.testing.assert_array_equal(res_seq, res_threads)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstarting <function main at 0x7f0b5871b9c0> with args () {}\nfinished <function main at 0x7f0b5871b9c0> in 0.0771 second(s)\n```\n:::\n:::\n\n\n# Conclusion\n\n::::: incremental\n- Everything is `awaitable` (coroutines, futures, tasks), i.e. can be simply run with `await`.\n- a task is a coroutine wrapped in a future, and scheduled to run in the event loop.\n- `asyncio` is a single-threaded asynchronous programming library, providing a simple way to write concurrent code for I/O bound tasks.\n\n    $\\Rightarrow$ We’ll see later that this programming model can be used for parallelism as well, and very easily.\n:::::\n\n# References {.allowframebreaks}\n\n",
    "supporting": [
      "3_Asynchronous_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}