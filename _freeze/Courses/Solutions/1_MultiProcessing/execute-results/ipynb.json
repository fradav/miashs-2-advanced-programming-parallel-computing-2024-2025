{
  "hash": "ac854916822b51e2329a209a3662899b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: MultiProcessing, Strong Scaling\n---\n\n\n## ⚠️⚠️⚠️⚠️ Attention ⚠️⚠️⚠️⚠️\n Under _Windows_, with python the multiprocessing module `multiprocessing` works in a normal script but **not in notebooks**.\n \nIf you absolutely must use Windows, use[WSL](https://docs.microsoft.com/fr-fr/windows/wsl/)\n\n# Strong Scaling\n\n## Prerequisites\n\nFor this TP, set the number of **physical** cores available (8 on the cluster nodes), not the number of logical cores.\n\n::: {#e50225d8 .cell execution_count=2}\n``` {.python .cell-code}\nncores = 4 # 8 on the cluster nodes\n```\n:::\n\n\n::: {#285e45f6 .cell execution_count=3}\n``` {.python .cell-code}\nimport math\n```\n:::\n\n\n# Introduction\n\n## Basic functions\n\nMake a function `is_prime` that tests whether an integer $n$ strictly greater than 2 is prime or not.\n\nHint: First check that it is not even, then list all odd numbers from 3 to $\\sqrt{n}$ (upper rounding) and test whether they are factors.\n\n::: {#f85e0554 .cell tags='[\"solution\"]' execution_count=4}\n``` {.python .cell-code}\ndef is_prime(n):\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(math.sqrt(n)) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n```\n:::\n\n\nMake a function `total_primes` that counts the number of primes in a list.\n\n::: {#9d52212b .cell tags='[\"solution\"]' execution_count=5}\n``` {.python .cell-code}\ndef total_primes(l):\n    n = 0\n    for i in l:\n        if (i > 0) & (i <= 2):\n            n=n+1\n        elif is_prime(i):\n            n=n+1                \n    return n\n```\n:::\n\n\nCalculate the number of primes from 1 to $N=100 000$ with this function\n\n::: {#64bf490f .cell execution_count=6}\n``` {.python .cell-code}\nN=100000\n```\n:::\n\n\n::: {#2e1099ff .cell execution_count=7}\n``` {.python .cell-code}\ntotal_primes(range(1,N+1))\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n9593\n```\n:::\n:::\n\n\n## Time measurement\n\nUse `%timeit` to measure the average time taken to count the number of primes up to $N=100000$.\n(note: by default, `timeit` repeats the calculation $7times{}10$ to obtain a reliable average. Please refer to the [magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) and [timeit](https://docs.python.org/3.9/library/timeit.html) docs).\n\nStore measurements using the -o option in timeit\n\n::: {#44f74e73 .cell execution_count=8}\n``` {.python .cell-code}\norig_time = %timeit -o total_primes(range(1,N+1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n72 ms ± 32.8 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\n# First steps\n\nOur first attempt at multiprocessing will involve partitioning the count into 2. We'll run two processes in parallel on $\\{1,...,N/2\\}$ and $\\{N/2+1,...,N\\}$.\n\nComplete the following code ([source](https://notebook.community/izapolsk/integration_tests/notebooks/MultiProcessing)).\n\nCheck the result and the performance gain with `%timeit`.\n\n::: {#b4908013 .cell execution_count=9}\n``` {.python .cell-code}\nfrom multiprocessing.pool import Pool\n\ndef split_total(N):\n    with Pool(2) as pool:\n        return sum(pool.map(total_primes, ...))\n```\n:::\n\n\n::: {#1d624335 .cell tags='[\"solution\"]' execution_count=10}\n``` {.python .cell-code}\nfrom multiprocessing.pool import Pool\n\ndef split_total(N):\n    with Pool(2) as pool:\n        return sum(pool.map(total_primes, [range(1,int(N/2)), range(int(N/2)+1,N+1)]))\n```\n:::\n\n\n::: {#636353ae .cell execution_count=11}\n``` {.python .cell-code}\nsplit_total(N)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n9593\n```\n:::\n:::\n\n\n::: {#10684d4b .cell execution_count=12}\n``` {.python .cell-code}\nsplit_time = %timeit -o split_total(N)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n51.6 ms ± 72.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\n::: {#766cb995 .cell execution_count=13}\n``` {.python .cell-code}\nprint(\"Gain with split : {:.1f}\".format(orig_time.average/split_time.average))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGain with split : 1.4\n```\n:::\n:::\n\n\n# Generalization\n\nGeneralize the function with partitioning into *n* tasks instead of just 2. We'll use a generalized `multi_process_list` function, which takes as arguments :\n- f` the main computation function, which takes an integer list as argument\n- n` the number of partitions (here, one partition = task)\n- par_f` a function which takes as argument a list and a number of partitions to be performed, and returns the list of partitions in this list\n- l` the list to be partitioned\n\n::: {#665c2dda .cell execution_count=14}\n``` {.python .cell-code}\ndef multi_process_list(f,n,par_f,l):\n    with Pool(ncores) as pool:\n        return sum(pool.map(...)\n```\n:::\n\n\nFirst, we write the `naive_par` partitioning function.\n\n::: {#93374ee7 .cell execution_count=15}\n``` {.python .cell-code}\ndef naive_par(lst,n):\n    return ...\n```\n:::\n\n\nWe'll use the `chunks` function, which partitions a list into chunks of fixed size (except for the last one).\n\nWe'll test the gain obtained with 8 tasks/partitions.\n\n::: {#1864bad5 .cell execution_count=16}\n``` {.python .cell-code}\ndef chunks(lst, m):\n    \"\"\"Yield successive m-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), m):\n        yield lst[i:i + m]\n```\n:::\n\n\nVérifier le fonctionnement de `naive_par`\n\n::: {#fd8237de .cell tags='[\"solution\"]' execution_count=17}\n``` {.python .cell-code}\ndef naive_par(lst,n):\n    return chunks(lst,int(len(lst)/n))\n```\n:::\n\n\n::: {#b147f8fd .cell tags='[\"solution\"]' execution_count=18}\n``` {.python .cell-code}\nlist(naive_par(range(1,100001),4))\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n[range(1, 25001),\n range(25001, 50001),\n range(50001, 75001),\n range(75001, 100001)]\n```\n:::\n:::\n\n\n::: {#98468667 .cell tags='[\"solution\"]' execution_count=19}\n``` {.python .cell-code}\ndef multi_process_list(f,n,par_f,l):\n    with Pool(n) as pool:\n        return sum(pool.map(f,par_f(l,n)))\n```\n:::\n\n\n::: {#76127463 .cell tags='[\"solution\"]' execution_count=20}\n``` {.python .cell-code}\nmulti_process_list(total_primes,ncores,naive_par,range(1,N+1))\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n9593\n```\n:::\n:::\n\n\n::: {#a969ad53 .cell execution_count=21}\n``` {.python .cell-code}\nmulti_time = %timeit -o multi_process_list(total_primes,ncores,naive_par,range(1,N+1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n39.5 ms ± 56.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\n::: {#6edd40ca .cell execution_count=22}\n``` {.python .cell-code}\nprint(\"Gain avec multi : {:.1f}\".format(orig_time.average/multi_time.average))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGain avec multi : 1.8\n```\n:::\n:::\n\n\nRepeat all calculations and payoff comparisons with $N=5000000$. To avoid long calculation times, we'll restrict ourselves to a single iteration (option `-r 1 -n 1` in `%timeit`).\n\n::: {#05ca03a9 .cell execution_count=23}\n``` {.python .cell-code}\nN = 5000000\n```\n:::\n\n\n::: {#272c162b .cell execution_count=24}\n``` {.python .cell-code}\norig_time = %timeit -r 1 -n 1 -o total_primes(range(1,N+1))\nsplit_time = %timeit -r 1 -n 1 -o split_total(N)\nmulti_time = %timeit -r 1 -n 1 -o multi_process_list(total_primes,ncores,naive_par,range(1,N+1))\n\nprint(\"Gain with split : {:.1f}\".format(orig_time.average/split_time.average))\nprint(\"Gain with multi : {:.1f}\".format(orig_time.average/multi_time.average))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n18.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n11.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n6.05 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\nGain with split : 1.7\nGain with multi : 3.1\n```\n:::\n:::\n\n\n# Optional refinement\n\n\nHow much time is spent on each task? Use the following function to get an idea. What do you observe?\n\n::: {#3cf1b8cf .cell execution_count=25}\n``` {.python .cell-code}\ndef timed_total_primes(l):\n    %timeit -r 1 -n 1 total_primes(l)\n    return 0\n```\n:::\n\n\n::: {#3277d04c .cell tags='[\"solution\"]' execution_count=26}\n``` {.python .cell-code}\nmulti_process_list(timed_total_primes,ncores,naive_par,range(1,N+1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.47 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n4.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n5.22 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n6.03 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n0\n```\n:::\n:::\n\n\nHow can we solve this problem?\n\nFind a simple solution that requires only one line of code. Check the execution times of individual tasks.\n\nCompare again with $N = 10000000$ (which will take about 1 minute sequentially).\n\n::: {#1c769558 .cell tags='[\"solution\"]' execution_count=27}\n``` {.python .cell-code}\nimport random\n\nN = 10000000\n\nshuffled = random.sample(range(1,N+1),N)\n```\n:::\n\n\n::: {#b610d4a0 .cell tags='[\"solution\"]' execution_count=28}\n``` {.python .cell-code}\nmulti_process_list(total_primes,ncores,naive_par,shuffled)\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n664580\n```\n:::\n:::\n\n\n::: {#b92bf6b8 .cell tags='[\"solution\"]' execution_count=29}\n``` {.python .cell-code}\ntemps_shuffled = %timeit -r 1 -n 1 -o multi_process_list(total_primes,ncores,naive_par,shuffled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n13.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n```\n:::\n:::\n\n\n::: {#cb1efcc1 .cell tags='[\"solution\"]' execution_count=30}\n``` {.python .cell-code}\nmulti_process_list(timed_total_primes,ncores,naive_par,shuffled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n12.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n12.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n12 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n12.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n0\n```\n:::\n:::\n\n\n::: {#d7b3ffc0 .cell tags='[\"solution\"]' execution_count=31}\n``` {.python .cell-code}\nshuffled = random.sample(range(1,N+1),N)\norig_time = %timeit -r 1 -n 1 -o total_primes(range(1,N+1))\nmulti_time = %timeit -r 1 -n 1 -o multi_process_list(total_primes,ncores,naive_par,range(1,N+1))\nshuffled_time = %timeit -r 1 -n 1 -o multi_process_list(total_primes,ncores,naive_par,shuffled)\n\nprint(\"Gain with multi : {:.1f}\".format(orig_time.average/multi_time.average))\nprint(\"Gain with shuffled : {:.1f}\".format(orig_time.average/shuffled_time.average))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n50 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n16.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n13.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\nGain with multi : 3.1\nGain with shuffled : 3.7\n```\n:::\n:::\n\n\n# Recreational interlude\n\nIf you have a CPU with SMT (Hyperthreading), redo the measurements with `ncores` equal to the number of logic cores, and explain the results.\n\n::: {#5e2a8297 .cell tags='[\"solution\"]' execution_count=32}\n``` {.python .cell-code}\nncores = 8 # On a machine with 4 physical cores/8 logical cores\n\nshuffled = random.sample(range(1,N+1),N)\norig_time = %timeit -r 1 -n 1 -o total_primes(range(1,N+1))\nmulti_time = %timeit -r 1 -n 1 -o multi_process_list(total_primes,ncores,naive_par,range(1,N+1))\nshuffled_time = %timeit -r 1 -n 1 -o multi_process_list(total_primes,ncores,naive_par,shuffled)\n\nprint(\"Gain with multi : {:.1f}\".format(orig_time.average/multi_time.average))\nprint(\"Gain with shuffled : {:.1f}\".format(orig_time.average/shuffled_time.average))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n50.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n8.38 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n7.71 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\nGain with multi : 6.0\nGain with shuffled : 6.5\n```\n:::\n:::\n\n\n---\njupyter:\n  kernelspec:\n    display_name: Python 3 (ipykernel)\n    language: python\n    name: python3\n    path: /nfs/home/collinf/micromamba/envs/miashs-hpc/share/jupyter/kernels/python3\n  language_info:\n    codemirror_mode:\n      name: ipython\n      version: 3\n    file_extension: .py\n    mimetype: text/x-python\n    name: python\n    nbconvert_exporter: python\n    pygments_lexer: ipython3\n    version: 3.12.5\n---\n",
    "supporting": [
      "1_MultiProcessing_files/figure-ipynb"
    ],
    "filters": []
  }
}