{
  "hash": "f064a3d1e8282f5124a5b28cacd926b3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Multiprocessing in Python 3\nsubtitle: Introduction to the `multiprocessing` module\njupyter: python3\n---\n\n\n\n\n# Multiprocessing in Python 3\n\n## Threads vs Processes\n\n* Thread\n  * Is bound to processor that python process running on\n  * Is controlled by Global Interpreter Lock (GIL)\n    * Single python bytecode executed at a time by any thread\n    \n* Process\n  * Uses multiple processors\n  * Concurrency between threads and processes (local and remote)\n  * Ignores GIL\n\n::: {#617a3265 .cell slideshow='{\"slide_type\":\"slide\"}' execution_count=2}\n``` {.python .cell-code}\nfrom os import getpid, getppid\nfrom time import sleep\n\ndef printer(val, wait=0):\n    sleep(wait)\n    print('Pid: {}, PPid: {}, Value: {}'\n          .format(getpid(), getppid(), val))\n```\n:::\n\n\n## Process Instantiation\n\nLet's start with most basic example of spawning new process to run a function\n\n::: {#0929969c .cell slideshow='{\"slide_type\":\"\"}' execution_count=3}\n``` {.python .cell-code}\nfrom multiprocessing import Process\n\nprint('Starting demo...')\np = Process(target=printer, args=('hello demo',))\np.start()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStarting demo...\n```\n:::\n:::\n\n\n### Process timing\n\n- Use printer's delay to see process timing\n- Track multiple process objects\n- Execute code in main process while chile process is running\n- Use Process.join() to wait for processes to finish\n\n::: {#1cecf849 .cell slideshow='{\"slide_type\":\"subslide\"}' execution_count=4}\n``` {.python .cell-code}\nproc_list = []\nfor values in [('immediate', 0), ('delayed', 2), ('eternity', 5)]:\n    p = Process(target=printer, args=values)\n    proc_list.append(p)\n    p.start()  # start execution of printer\n\nprint('Not waiting for proccesses to finish...')\n    \n[p.join() for p in proc_list]\n\nprint('After processes...')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPid: 187574, PPid: 187540, Value: immediate\nNot waiting for proccesses to finish...\nPid: 187577, PPid: 187540, Value: delayed\nPid: 187580, PPid: 187540, Value: eternity\nAfter processes...\n```\n:::\n:::\n\n\n## Process Pool\n\n- Worker processes instead of direct instantiation\n- Context manager to handle starting/joining child processes\n- Pool.map() works like default python `map(f, args)` function\n- Pool.map() Does not unpack args\n\n::: {#99bc364e .cell slideshow='{\"slide_type\":\"subslide\"}' execution_count=5}\n``` {.python .cell-code}\nfrom multiprocessing.pool import Pool\n\nwith Pool(3) as pool:\n    pool.map(printer, ['Its', ('A', 5), 'Race'])\n    # each worker process executes one function\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPid: 187590, PPid: 187540, Value: ItsPid: 187591, PPid: 187540, Value: ('A', 5)Pid: 187592, PPid: 187540, Value: Race\n\n\n```\n:::\n:::\n\n\n## Process + args/kwargs iteration with starmap\n\n::: {#c8dae6fe .cell slideshow='{\"slide_type\":\"fragment\"}' execution_count=6}\n``` {.python .cell-code}\nwith Pool(2) as pool:\n    pool.starmap(printer, [('Its',), ('A', 2), ('Race',)])\n    # one worker will execute 2 functions, one worker will execute the 'slow' function\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPid: 187608, PPid: 187540, Value: Its\nPid: 187608, PPid: 187540, Value: Race\nPid: 187609, PPid: 187540, Value: A\n```\n:::\n:::\n\n\n## Thread Pool\n\n::: {#b6000080 .cell execution_count=7}\n``` {.python .cell-code}\nfrom multiprocessing.pool import ThreadPool\n\n# Threadpool instead of process pool, same interface\nwith ThreadPool(2) as pool:\n    pool.starmap(printer, [('Its', 5), ('A', 10), ('Race', 15)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPid: 187540, PPid: 187537, Value: Its\nPid: 187540, PPid: 187537, Value: A\nPid: 187540, PPid: 187537, Value: Race\n```\n:::\n:::\n\n\n## Starmap is the bomb\n\n::: {#241e2366 .cell slideshow='{\"slide_type\":\"fragment\"}' execution_count=8}\n``` {.python .cell-code}\ndef pretend_delete_method(provider, vm_name):\n    print('Pretend delete: {} on {}. (Pid: {})'\n          .format(vm_name, provider, getpid()))    \n    \n# Assuming we fetched a list of vm names on providers we want to cleanup...\nexample_provider_vm_lists = dict(\n    vmware=['test_vm_1', 'test_vm_2'],\n    rhv=['test_vm_3', 'test_vm_4'],\n    osp=['test_vm_5', 'test_vm_6'],\n)\n```\n:::\n\n\n::: {#3a0810f0 .cell slideshow='{\"slide_type\":\"subslide\"}' execution_count=9}\n``` {.python .cell-code}\n# don't hate me for nested comprehension here - building tuples of provider+name\nfrom multiprocessing.pool import ThreadPool\n\n# Threadpool instead of process pool, same interface\nwith ThreadPool(6) as pool:\n    pool.starmap(\n        pretend_delete_method, \n        [(key, vm) \n         for key, vms \n         in example_provider_vm_lists.items() \n         for vm in vms]\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPretend delete: test_vm_1 on vmware. (Pid: 187540)\nPretend delete: test_vm_2 on vmware. (Pid: 187540)\nPretend delete: test_vm_3 on rhv. (Pid: 187540)\nPretend delete: test_vm_4 on rhv. (Pid: 187540)\nPretend delete: test_vm_5 on osp. (Pid: 187540)\nPretend delete: test_vm_6 on osp. (Pid: 187540)\n```\n:::\n:::\n\n\n## Locking\n\n- semaphore-type object that can be acquired and released\n- When acquired, only thread that has the lock can run\n- Necessary when using shared objects\n\n::: {#2f2fd1e1 .cell slideshow='{\"slide_type\":\"subslide\"}' execution_count=10}\n``` {.python .cell-code}\ndef not_safe_printing_method(provider, vm_name):\n        print('Pretend delete: {} on {}. (Pid: {})'\n              .format(vm_name, provider, getpid()))\n```\n:::\n\n\n::: {#57bf869f .cell slideshow='{\"slide_type\":\"fragment\"}' execution_count=11}\n``` {.python .cell-code}\nwith Pool(6) as pool:\n    pool.starmap(\n        not_safe_printing_method, \n        [(key, vm) for key, vms in example_provider_vm_lists.items() for vm in vms])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPretend delete: test_vm_2 on vmware. (Pid: 187658)Pretend delete: test_vm_3 on rhv. (Pid: 187659)Pretend delete: test_vm_4 on rhv. (Pid: 187660)Pretend delete: test_vm_1 on vmware. (Pid: 187657)Pretend delete: test_vm_5 on osp. (Pid: 187661)\n\nPretend delete: test_vm_6 on osp. (Pid: 187662)\n\n\n\n```\n:::\n:::\n\n\n::: {#4aa7814c .cell slideshow='{\"slide_type\":\"subslide\"}' execution_count=12}\n``` {.python .cell-code}\n# Printing is thread safe, but will sometimes print separate messages on the same line (above)\n# Use a lock around print\nfrom multiprocessing import Lock\n\nlock = Lock()\n\ndef safe_printing_method(provider, vm_name):\n    with lock:\n        print('Pretend delete: {} on {}. (Pid: {})'\n              .format(vm_name, provider, getpid()))\n```\n:::\n\n\n::: {#d9726ca9 .cell slideshow='{\"slide_type\":\"fragment\"}' execution_count=13}\n``` {.python .cell-code}\nwith Pool(6) as pool:\n    pool.starmap(\n        safe_printing_method, \n        [(key, vm) for key, vms in example_provider_vm_lists.items() for vm in vms])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPretend delete: test_vm_1 on vmware. (Pid: 187690)\nPretend delete: test_vm_2 on vmware. (Pid: 187691)\nPretend delete: test_vm_3 on rhv. (Pid: 187692)\nPretend delete: test_vm_4 on rhv. (Pid: 187693)\nPretend delete: test_vm_5 on osp. (Pid: 187694)\nPretend delete: test_vm_6 on osp. (Pid: 187695)\n```\n:::\n:::\n\n\n# Queues\n\n- Store data/objects in child thread/processes and retrieve in parent\n- FIFO stack with put, get, and empty methods\n\n::: {#9151f8e6 .cell execution_count=14}\n``` {.python .cell-code}\n# Standard Queue\nimport queue\nq = queue.Queue()\nfor x in range(4):\n    q.put(x)\nprint(\"Members of the queue:\")\ny=z=q.qsize()\n\nfor n in list(q.queue):\n    print(n, end=\" \")\nprint(\"\\nSize of the queue:\")\nprint(q.qsize())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMembers of the queue:\n0 1 2 3 \nSize of the queue:\n4\n```\n:::\n:::\n\n\n# Reminder on python serialization : \"Pickling\"\n\nSo what is pickling? Pickling is the serializing and de-serializing of python objects to a byte stream. Unpicking is the opposite.\n\nPickling is used to store python objects. This means things like lists, dictionaries, class objects, and more.\n\n::: {#ee8ab4f6 .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=15}\n``` {.python .cell-code}\nimport pickle # First, import pickle to use it\n```\n:::\n\n\n::: {#9766fedf .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=16}\n``` {.python .cell-code}\nexample_dict = {1:\"6\",2:\"2\",3:\"f\"} # we define an example dictionary, which is a Python object\n```\n:::\n\n\n::: {#c5096f01 .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=17}\n``` {.python .cell-code}\npickle_out = open(\"dict.pickle\",\"wb\") # Next, we open a file (note that we open to write bytes in Python 3+)\n```\n:::\n\n\n::: {#e3eacd2e .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=18}\n``` {.python .cell-code}\npickle.dump(example_dict, pickle_out) # then we use pickle.dump() to put the dict into opened file, then close.\n```\n:::\n\n\n::: {#65250637 .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=19}\n``` {.python .cell-code}\npickle_out.close() # and close(), it's very important to NOT forget to close your opened files.\n```\n:::\n\n\nThe above code will save the pickle file for us, now we need to cover how to access the pickled file:\n\n::: {#015dc1ef .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=20}\n``` {.python .cell-code}\npickle_in = open(\"dict.pickle\",\"rb\") # Open the pickle file\n```\n:::\n\n\n::: {#5e7a7d2b .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=21}\n``` {.python .cell-code}\nexample_dict = pickle.load(pickle_in) # Use pickle.load() to load it to a var.\n```\n:::\n\n\nThat's all there is to it, now you can do things like:\n\n::: {#d0489a1b .cell cell_style='center' slideshow='{\"slide_type\":\"fragment\"}' execution_count=22}\n``` {.python .cell-code}\nprint(example_dict)\nprint(example_dict[3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{1: '6', 2: '2', 3: 'f'}\nf\n```\n:::\n:::\n\n\nThis shows that we've retained the dict data-type.\n\n## Queues\n\n- multiprocessing.Queue\n  - **cannot be pickled** and thus can't be passed to Pool methods\n  - can deadlock with improper join use\n- multiprocessing.Manager.Queue\n  - is proxy, can be pickled\n  - can be shared between processes\n  \n$\\Longrightarrow$ prefer the use of managed queues\n\n## Short example of queue use\n\nIn this example we share a managed queue between processes, and each process can randomly put a boolean (indicating a failure for example) in this queue.\n\nThis is our dummy function to parallelize, getting the shared queue as an additional argument\n\n::: {#32d537c3 .cell slideshow='{\"slide_type\":\"-\"}' execution_count=23}\n``` {.python .cell-code}\nfrom random import randint\n\ndef multiple_output_method(provider, vm_name, fail_queue):\n    # random success of called method\n    if randint(0, 1):\n        return True\n    else:\n        # Store our failure vm on the queue\n        fail_queue.put(vm_name)\n        return None\n```\n:::\n\n\nWe need to instantiate the manager, and create a queue from it\n\n::: {#7bb8f1ca .cell slideshow='{\"slide_type\":\"-\"}' execution_count=24}\n``` {.python .cell-code}\nfrom multiprocessing import Manager\n\n# Create instance of manager\nmanager = Manager()\n\n# Create queue object to give to child processes\nqueue_for_failures = manager.Queue()\n```\n:::\n\n\nThe (multi)-processing is there\n\n::: {#c7e9356d .cell slideshow='{\"slide_type\":\"-\"}' execution_count=25}\n``` {.python .cell-code}\nwith Pool(2) as pool:\n    results = pool.starmap(\n        multiple_output_method, \n        [(key, vm, queue_for_failures)\n         for key, vms\n         in example_provider_vm_lists.items()\n         for vm in vms]\n    )\n```\n:::\n\n\nNow what's up ? \n\nResults :\n\n::: {#726f003f .cell slideshow='{\"slide_type\":\"fragment\"}' execution_count=26}\n``` {.python .cell-code}\nprint('Results are in: {}'.format(results))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResults are in: [None, None, True, True, None, None]\n```\n:::\n:::\n\n\nAnd what is in the queue ?\n\n::: {#db546f6d .cell slideshow='{\"slide_type\":\"fragment\"}' execution_count=27}\n``` {.python .cell-code}\nfailed_vms = []\n# get items from the queue while its not empty\nwhile not queue_for_failures.empty():\n    failed_vms.append(queue_for_failures.get())\n    \nprint('Failures are in: {}'.format(failed_vms))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFailures are in: ['test_vm_1', 'test_vm_2', 'test_vm_5', 'test_vm_6']\n```\n:::\n:::\n\n\n",
    "supporting": [
      "1_MultiProcessing_tutorial-sol_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}