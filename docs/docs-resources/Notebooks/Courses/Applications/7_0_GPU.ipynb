{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPU computing with Numba (introduction)\n",
        "\n",
        "François-David Collin (CNRS, IMAG, Paul-Valéry Montpellier 3\n",
        "University)  \n",
        "Ghislain Durif (CNRS, LBMC)  \n",
        "Monday, August 26, 2024\n",
        "\n",
        "> “[Numba](https://numba.pydata.org/) is an open source JIT compiler\n",
        "> that translates a subset of Python and NumPy code into fast machine\n",
        "> code.”\n",
        "\n",
        "Numba offers GPU support (through CUDA). See the official\n",
        "[documentation](https://numba.pydata.org/numba-doc/latest/cuda/index.html)\n",
        "or this [NYU course](https://nyu-cds.github.io/python-numba/05-cuda/)\n",
        "\n",
        "## Terminology\n",
        "\n",
        "Several important terms in the topic of CUDA programming are listed\n",
        "here:\n",
        "\n",
        "-   host: the CPU along with the system memory (RAM)\n",
        "\n",
        "-   device: the GPU\n",
        "\n",
        "-   host memory: the system main memory\n",
        "\n",
        "-   device memory: onboard memory on a GPU card\n",
        "\n",
        "-   kernel: a GPU function launched by the host and executed on the\n",
        "    device\n",
        "\n",
        "-   device function: a GPU function executed on the device which can\n",
        "    only be called from the device (i.e. from a kernel or another device\n",
        "    function)\n",
        "\n",
        "## First example: array reduction\n",
        "\n",
        "In our examples: - 128 threads (on 64 CPU cores) to run CPU computing -\n",
        "Nvidia A10 GPU to run GPU computing\n",
        "\n",
        "|  |  |\n",
        "|------------------------------------|------------------------------------|\n",
        "| FP32 | 31.2 teraFLOPS |\n",
        "| TF32 Tensor Core | 62.5 teraFLOPS |\n",
        "| BFLOAT16 Tensor Core | 125 teraFLOPS |\n",
        "| FP16 Tensor Core | 125 teraFLOPS |\n",
        "| INT8 Tensor Core | 250 TOPS |\n",
        "| INT4 Tensor Core | 500 TOPS |\n",
        "| RT Core | 72 RT Cores |\n",
        "| Encode/decode | 1 encoder2 decoder (+AV1 decode) |\n",
        "| GPU memory | 24GB GDDR6 |\n",
        "| GPU memory bandwidth | 600GB/s |\n",
        "| Interconnect | PCIe Gen4 64GB/s |\n",
        "| Form factors | Single-slot, full-height, full-length (FHFL) |\n",
        "| Max thermal design power (TDP) | 150W |\n",
        "| vGPU software support | NVIDIA Virtual PC, NVIDIA Virtual Applications, NVIDIA RTX Virtual Workstation, NVIDIA Virtual Compute Server, NVIDIA AI Enterprise |\n",
        "\n",
        "A10 Technical Specifications and Features\n",
        "\n",
        "### requirements"
      ],
      "id": "8168f8c0-5973-4447-9ba3-920bdd1d6360"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "from numba import cuda, set_num_threads\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"notebook+plotly_mimetype+svg\"\n",
        "\n",
        "set_num_threads(128)\n",
        "from numba.core.errors import NumbaPerformanceWarning\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)"
      ],
      "id": "20428c0f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reduction algorithm"
      ],
      "id": "3966ea95-1301-46e5-b6d1-a4fd5d44189c"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@cuda.reduce\n",
        "def sum_reduce(a, b):\n",
        "    return a + b"
      ],
      "id": "c1c6f937"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Attention**: the first call to `sum_reduce` will trigger a compilation\n",
        "step so with Numba operators, we always need to run a blank run first\n",
        "(on small data to avoid high computation time)."
      ],
      "id": "590a83ce-b7f0-4eda-97c1-047ba41d2481"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# blank run\n",
        "A = np.arange(1,10).astype(np.float32)\n",
        "sum_reduce(A)"
      ],
      "id": "a9030b19"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Toy example"
      ],
      "id": "bb86e32f-b015-4994-83f5-99fd69ad27bd"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# generate a vector array of dimension 1E7 with random float32 elements\n",
        "A = np.random.normal(loc=0, scale=10, size=1000000).astype(np.float32)"
      ],
      "id": "81d0e0bc"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# numpy sum reduction\n",
        "t1 = %timeit -r 5 -n 800 -q -o A.sum()"
      ],
      "id": "06fc2847"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum_reduce(A)\n",
        "# cuda sum reduction\n",
        "t2 = %timeit -r 5 -n 800 -q -o sum_reduce(A)"
      ],
      "id": "b8506451"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Which one is faster ?"
      ],
      "id": "8a051174-d67e-42f2-b9b4-067a9923a2f6"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# numpy sum reduction\n",
        "t1"
      ],
      "id": "475b5a75"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cuda sum reduction\n",
        "t2"
      ],
      "id": "9d63839c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The GPU is slower????\n",
        "\n",
        "### Benchmark numpy array sum vs cuda sum reduction"
      ],
      "id": "6fd3d2c7-e38d-4944-8232-69f6ec0955cb"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark1(N):\n",
        "    A = np.random.normal(loc=0, scale=10, size=N).astype(np.float32)\n",
        "    # numpy sum reduction\n",
        "    t1 = %timeit -r 5 -n 10 -q -o A.sum()\n",
        "    # cuda sum reduction\n",
        "    t2 = %timeit -r 5 -n 10 -q -o sum_reduce(A)\n",
        "    # output\n",
        "    return t1.average, t2.average"
      ],
      "id": "698d3a58"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Checking increasing vector size"
      ],
      "id": "8a027d70-f921-46d9-bec0-43e68304de72"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Powers of 2 vector\n",
        "vec_size = [2**exp for exp in range(12,28)]"
      ],
      "id": "d6a4242d"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the list size candidates\n",
        "import plotly.express as px\n",
        "\n",
        "px.scatter(y=vec_size,width=600,labels={'y':\"Data length\",'x':\"Vector index\"},log_y=True)"
      ],
      "id": "88734f51"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run the benchmark"
      ],
      "id": "303e428b-0d6a-409e-8f9c-df28a2d4e2d7"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the benchmark\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "res = []\n",
        "\n",
        "for N in tqdm(vec_size):\n",
        "    \n",
        "    time_res = benchmark1(N)\n",
        "    \n",
        "    res.append({\n",
        "        'N': N,\n",
        "        'numpy': time_res[0],\n",
        "        'cuda': time_res[1]\n",
        "    })"
      ],
      "id": "863382d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Results"
      ],
      "id": "3ce958d8-a93e-4685-a79c-e6b356223d4e"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_res = pd.DataFrame(res)\n",
        "px.line(df_res, x='N', y=['numpy', 'cuda'], log_y=True, log_x=True, width=600)"
      ],
      "id": "b87252de"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**It is confirmed!!! Why bother using GPU???**\n",
        "\n",
        "#### Any idea ?\n",
        "\n",
        "### Bottleneck\n",
        "\n",
        "-   Host to device (GPU) memory copy\n",
        "\n",
        "### Solution\n",
        "\n",
        "-   Copy data to device (GPU) before running the computations\n",
        "\n",
        "See Numba dedicated\n",
        "[page](https://numba.pydata.org/numba-doc/latest/cuda/memory.html) for\n",
        "memory management."
      ],
      "id": "50d6c222-14fe-452d-a402-dd69d2997cf8"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark2(N):\n",
        "    print(f\"sum of {N} elements\")\n",
        "    A = np.random.normal(loc=0, scale=10, size=N).astype(np.float32)\n",
        "    # numpy sum reduction\n",
        "    t1 = %timeit -r 5 -n 10 -q -o A.sum()\n",
        "    # copy data to device\n",
        "    A_gpu = cuda.to_device(A)\n",
        "    # cuda sum reduction\n",
        "    t2 = %timeit -r 5 -n 10 -q -o sum_reduce(A_gpu)\n",
        "    # output\n",
        "    return t1.average, t2.average"
      ],
      "id": "fd43bb62"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the benchmark\n",
        "res = []\n",
        "\n",
        "for N in tqdm(vec_size):\n",
        "    \n",
        "    time_res = benchmark2(N)\n",
        "    \n",
        "    res.append({\n",
        "        'N': N,\n",
        "        'numpy': time_res[0],\n",
        "        'cuda': time_res[1]\n",
        "    })"
      ],
      "id": "b839a875"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results\n",
        "df_res2 = pd.DataFrame(res)\n",
        "px.line(df_res2, x='N', y=['numpy', 'cuda'], log_y=True, log_x=True, width=600)"
      ],
      "id": "c0b34356"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**GPU is better to do high throughput computing with larger matrices.**\n",
        "\n",
        "### GPU memory overflow"
      ],
      "id": "332aee67-39fd-4b65-8f6a-9ccbd32a3590"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "Note": "GPU memory overflow on small gpu"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    A = np.random.normal(loc=0, scale=10, size=int(2E9)).astype(np.float32)\n",
        "    sum_reduce(A)\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "id": "042d924f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**To avoid memory overflow:** -\n",
        "[KeOps](https://www.kernel-operations.io/keops/index.html): Kernel\n",
        "Operations (including matrix operations and reduction) on the GPU, with\n",
        "autodiff, without memory overflows"
      ],
      "id": "b2069fdc-d639-4b04-a7f6-60a37dc978d7"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: CPU memory overflow\n",
        "try:\n",
        "    A = np.random.normal(loc=0, scale=10, size=int(1E12)).astype(np.float32)\n",
        "    sum_reduce(A)\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "id": "8e70b09c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Complex operation on GPU ?\n",
        "\n",
        "$$\\sum_i \\vert x_i \\vert = \\sum_i (-1)^{I_{\\{x_i < 0\\}}} x_i = \\sum_{i,x_i \\geq 0} x_i - \\sum_{i,x_i < 0} x_i$$\n",
        "\n",
        "Example: if $x = [-1, 3, 5, -2]$ then we want to compute $1 + 3 + 5 + 2$"
      ],
      "id": "0d31106a-3371-4fca-9fde-52ab66938620"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numpy reduce\n",
        "def numpy_reduce(vec):\n",
        "    return (vec * np.where(vec < 0, -1, 1)).sum()\n",
        "\n",
        "# numba cpu reduce\n",
        "from numba import njit, prange, set_num_threads\n",
        "\n",
        "set_num_threads(8)\n",
        "\n",
        "@njit(parallel=True)\n",
        "def numba_reduce(A):\n",
        "    s = 0\n",
        "    # Without \"parallel=True\" in the jit-decorator\n",
        "    # the prange statement is equivalent to range\n",
        "    for i in prange(A.shape[0]):\n",
        "        if A[i] < 0:\n",
        "            s += -A[i]\n",
        "        else:\n",
        "            s += A[i]\n",
        "    return s\n",
        "\n",
        "# cuda reduce\n",
        "@cuda.reduce\n",
        "def cuda_reduce(a, b):\n",
        "    if b < 0:\n",
        "        return a - b\n",
        "    else:\n",
        "        return a + b\n",
        "    \n",
        "A = np.random.normal(loc=0, scale=10, size=1000).astype(np.float32)\n",
        "numba_reduce(A)\n",
        "cuda_reduce(A)"
      ],
      "id": "2d4f4b02"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# benchmark\n",
        "def benchmark3(N):\n",
        "    print(f\"complex operations on {N} elements\")\n",
        "    A = np.random.normal(loc=0, scale=10, size=N).astype(np.float32)\n",
        "    # numpy reduction\n",
        "    t1 = %timeit -r 2 -n 5 -q -o numpy_reduce(A)\n",
        "    # numba reduction\n",
        "    t2 = %timeit -r 2 -n 5 -q -o numba_reduce(A)\n",
        "    # cuda reduction\n",
        "    A_gpu = cuda.to_device(A)\n",
        "    t3 = %timeit -r 2 -n 5 -q -o cuda_reduce(A_gpu)\n",
        "    # output\n",
        "    return t1.average, t2.average, t3.average"
      ],
      "id": "658f0e92"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the benchmark\n",
        "res = []\n",
        "resspeedup = []\n",
        "for N in tqdm(vec_size):\n",
        "    \n",
        "    time_res = benchmark3(N)\n",
        "    \n",
        "    res.append({\n",
        "        'N': N,\n",
        "        'numpy': time_res[0],\n",
        "        'numba_128c': time_res[1],\n",
        "        'cuda': time_res[2],\n",
        "    })\n",
        "    resspeedup.append({\n",
        "        'N': N,\n",
        "        'numpy/numba': time_res[0]/time_res[1],\n",
        "        'numpy/cuda': time_res[0]/time_res[2]\n",
        "    })"
      ],
      "id": "c32cdc8e"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results\n",
        "df_res = pd.DataFrame(res)\n",
        "fig = px.line(df_res, x='N', y=['numpy', 'numba_128c', 'cuda'], log_y=True, log_x=True, width=600)\n",
        "fig.show()\n",
        "df_resspeedup = pd.DataFrame(resspeedup)\n",
        "fig = px.line(df_resspeedup, x='N', y=['numpy/numba', 'numpy/cuda'], log_y=True, log_x=True, width=600)\n",
        "fig.show()"
      ],
      "id": "ad8e3a72"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numba for GPU: next level\n",
        "\n",
        "### GPU management"
      ],
      "id": "f6907435-4338-41c8-8be7-c473f70ff568"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to check available GPU\n",
        "from numba import cuda\n",
        "for gpu in cuda.list_devices():\n",
        "    print(gpu.name)\n",
        "    \n",
        "cuda.get_current_device().name"
      ],
      "id": "9492909a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kernel declaration\n",
        "\n",
        "kernel function = GPU function meant to be called from CPU code\n",
        "\n",
        "Characteristics: - kernels **cannot explicitly return a value** (all\n",
        "result data must be written to an array passed to the function) -\n",
        "kernels **explicitly declare their thread hierarchy when called**:\n",
        "i.e. the number of thread blocks and the number of threads per block\n",
        "\n",
        "**Attention**: Kernel function are compiled on their first call, we\n",
        "always need to run a blank run first (on small data to avoid high\n",
        "computation time)."
      ],
      "id": "bb83cb51-014c-4a8e-be75-0a25402d2236"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "\n",
        "@cuda.jit\n",
        "def my_kernel(io_array):\n",
        "    \"\"\"\n",
        "    Code for kernel.\n",
        "    \"\"\"\n",
        "    # code here"
      ],
      "id": "1bfce648"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "\n",
        "# Create the data array - usually initialized some other way\n",
        "data = numpy.ones(256)\n",
        "\n",
        "# Set the number of threads in a block\n",
        "threadsperblock = 32 \n",
        "\n",
        "# Calculate the number of thread blocks in the grid\n",
        "blockspergrid = (data.size + (threadsperblock - 1)) // threadsperblock\n",
        "\n",
        "# Now start the kernel\n",
        "my_kernel[blockspergrid, threadsperblock](data)\n",
        "\n",
        "# Print the result\n",
        "print(data)"
      ],
      "id": "b5b3fe63"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Important**: you have to choose the number of blocks per grid (and\n",
        "hence the block size) and the number of threads per block. The product\n",
        "of the two will give the total number of threads launched.\n",
        "\n",
        "### Choosing the block size\n",
        "\n",
        "[Credit](https://nyu-cds.github.io/python-numba/05-cuda/)\n",
        "\n",
        "The two-level thread hierarchy is important for the following reasons:\n",
        "\n",
        "-   On the software side, the block size determines how many threads\n",
        "    share a given area of shared memory.\n",
        "-   On the hardware side, the block size must be large enough for full\n",
        "    occupation of execution units; recommendations can be found in the\n",
        "    CUDA C Programming Guide.\n",
        "\n",
        "The block size you choose depends on a range of factors, including:\n",
        "\n",
        "-   The size of the data array\n",
        "-   The size of the shared mempory per block (e.g. 64KB)\n",
        "-   The maximum number of threads per block supported by the hardware\n",
        "    (e.g. 512 or 1024)\n",
        "-   The maximum number of threads per multiprocessor (MP) (e.g. 2048)\n",
        "-   The maximum number of blocks per MP (e.g. 32)\n",
        "-   The number of threads that can be executed concurrently (a “warp”\n",
        "    i.e. 32)\n",
        "\n",
        "The execution of threads in a warp has a big effect on the computational\n",
        "throughput. If all threads in a warp are executing the same instruction\n",
        "then they can all be executed in parallel. But if one or more threads is\n",
        "executing a different instruction, the warp has to be split into groups\n",
        "of threads, and these groups execute serially.\n",
        "\n",
        "**Rules of thumb for threads per block:**\n",
        "\n",
        "-   Should be a round multiple of the warp size (32)\n",
        "-   A good place to start is 128-512 but benchmarking is required to\n",
        "    determine the optimal value.\n",
        "\n",
        "Each streaming multiprocessor (SP) on the GPU must have enough active\n",
        "warps to achieve maximum throughput. In other words, the blocksize is\n",
        "usually selected to maximize the “occupancy”. See the [CUDA Occupancy\n",
        "Calculator\n",
        "spreadsheet](http://developer.download.nvidia.com/compute/cuda/CUDA_Occupancy_calculator.xls)for\n",
        "more details.\n",
        "\n",
        "### Thread positioning\n",
        "\n",
        "[Credit](https://nyu-cds.github.io/python-numba/05-cuda/)\n",
        "\n",
        "When running a kernel, the kernel function’s code is executed by every\n",
        "thread once. It therefore has to know which thread it is in, in order to\n",
        "know which array element(s) it is responsible for. More complex\n",
        "algorithms may define more complex responsibilities, but the underlying\n",
        "principle is the same.\n",
        "\n",
        "To help deal with multi-dimensional arrays, CUDA allows you to specify\n",
        "multi-dimensional blocks and grids. In the example above, you could make\n",
        "blockspergrid and threadsperblock tuples of one, two or three integers.\n",
        "Compared to 1-dimensional declarations of equivalent sizes, this doesn’t\n",
        "change anything to the efficiency or behaviour of generated code, but\n",
        "can help you write your algorithms in a more natural way.\n",
        "\n",
        "### Matrix product\n",
        "\n",
        "Numpy version for comparison"
      ],
      "id": "0e88fc18-d400-4a7d-8da0-7bea1ae19de9"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# numpy version\n",
        "def numpy_matmul(A, B):\n",
        "    C = np.matmul(A, B)\n",
        "    return C"
      ],
      "id": "33efa081"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Naive cuda version"
      ],
      "id": "0b5f9c9d-04aa-441d-b6aa-348cc841bd3a"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def cuda_matmul(A, B, C):\n",
        "    \"\"\"Perform matrix multiplication of C = A * B\n",
        "    \"\"\"\n",
        "    row, col = cuda.grid(2)\n",
        "    if row < C.shape[0] and col < C.shape[1]:\n",
        "        tmp = 0.\n",
        "        for k in range(A.shape[1]):\n",
        "            tmp += A[row, k] * B[k, col]\n",
        "        C[row, col] = tmp"
      ],
      "id": "b18f18c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](attachment:../figs/matmul.png)\n",
        "[Credit](https://nyu-cds.github.io/python-numba/05-cuda/)\n",
        "\n",
        "#### Run"
      ],
      "attachments": {
        "../figs/matmul.png": {
          "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAH/CAIAAABYSQqVAAAAAXNSR0IB2cksfwAAAAlwSFlzAAAL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\n16i3oOQXARGwlMD/A81MOdtLLRB6AAAAAElFTkSuQmCC\n"
        }
      },
      "id": "a3b4fc87-6512-4675-9bee-a1742dca9555"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data 1000x1000 matrix\n",
        "A = np.random.normal(loc=0, scale=10, size=1000**2).astype(np.float32).reshape((1000,1000))\n",
        "B = np.random.normal(loc=0, scale=10, size=1000**2).astype(np.float32).reshape((1000,1000))"
      ],
      "id": "3c782f07"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# numpy run\n",
        "%timeit -r 5 -n 20 -q -o numpy_matmul(A, B)"
      ],
      "id": "455ac73d"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy the arrays to the device\n",
        "A_gpu = cuda.to_device(A)\n",
        "B_gpu = cuda.to_device(B)\n",
        "\n",
        "# Allocate memory on the device for the result\n",
        "C_gpu = cuda.device_array((24, 22))"
      ],
      "id": "74961067"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure the blocks\n",
        "import math\n",
        "threadsperblock = (16, 16)\n",
        "blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[0]))\n",
        "blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[1]))\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)"
      ],
      "id": "72128cab"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "# CUDA matrix multiplication\n",
        "#\n",
        "@cuda.jit\n",
        "def cuda_matmul1(A, B, C):\n",
        "    \"\"\"Perform square matrix multiplication of C = A * B\n",
        "    \"\"\"\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < C.shape[0] and j < C.shape[1]:\n",
        "        tmp = 0.\n",
        "        for k in range(A.shape[1]):\n",
        "            tmp += A[i, k] * B[k, j]\n",
        "        C[i, j] = tmp"
      ],
      "id": "9e692275"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cuda run\n",
        "%timeit -r 5 -n 20 -q -o cuda_matmul1[blockspergrid, threadsperblock](A_gpu, B_gpu, C_gpu)"
      ],
      "id": "a8ff77ef"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the result from the GPU\n",
        "C = C_gpu.copy_to_host()"
      ],
      "id": "c8f94739"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numba import cuda, float32\n",
        "\n",
        "# Controls threads per block and shared memory usage.\n",
        "# The computation will be done on blocks of TPBxTPB elements.\n",
        "TPB = 16\n",
        "\n",
        "@cuda.jit\n",
        "def cuda_fast_matmul(A, B, C):\n",
        "    # Define an array in the shared memory\n",
        "    # The size and type of the arrays must be known at compile time\n",
        "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
        "\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    bpg = cuda.gridDim.x    # blocks per grid\n",
        "\n",
        "    if x >= C.shape[0] and y >= C.shape[1]:\n",
        "        # Quit if (x, y) is outside of valid C boundary\n",
        "        return\n",
        "\n",
        "    # Each thread computes one element in the result matrix.\n",
        "    # The dot product is chunked into dot products of TPB-long vectors.\n",
        "    tmp = 0.\n",
        "    for i in range(bpg):\n",
        "        # Preload data into shared memory\n",
        "        sA[tx, ty] = A[x, ty + i * TPB]\n",
        "        sB[tx, ty] = B[tx + i * TPB, y]\n",
        "\n",
        "        # Wait until all threads finish preloading\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Computes partial product on the shared memory\n",
        "        for j in range(TPB):\n",
        "            tmp += sA[tx, j] * sB[j, ty]\n",
        "\n",
        "        # Wait until all threads finish computing\n",
        "        cuda.syncthreads()\n",
        "\n",
        "    C[x, y] = tmp"
      ],
      "id": "863294c0"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure the blocks\n",
        "threadsperblock = (TPB, TPB)\n",
        "blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[1]))\n",
        "blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[0]))\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# Start the kernel \n",
        "%timeit -r 5 -n 20 -q -o cuda_fast_matmul[blockspergrid, threadsperblock](A_gpu, B_gpu, C_gpu)"
      ],
      "id": "19f80194"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/fradav/.micromamba/envs/miashs-hpc/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  }
}